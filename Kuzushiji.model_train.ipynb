{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "### Model Training\n\nOnce your model is defined, it can be trained. This can happen on a single thread or on a parallel framework like Watson Machine Learning or Apache Spark. In the most simple case Model Definition and Model Training is just a couple of LOCs (lines of code) away. In the case of Watson Machine Learning or Apache Spark models might need to get serialized and transferred to another technology / framework.\n\nPlease specify and justify the technologies used for model definition and training in the ADD. \n\nOnce you think you have achieved a descent model performance save the notebook according to the process model\u2019s naming convention and proceed to the model evaluation task."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20210616230802-0000\nKERNEL_ID = 46b5313c-85df-4e15-8187-c2a5f5235476\nCollecting tensorflow\n  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 454.3 MB 32 kB/s s eta 0:00:01     |\u258b                               | 8.1 MB 14.7 MB/s eta 0:00:31                       | 41.1 MB 14.7 MB/s eta 0:00:29 |\u2588\u2588\u2588\u2588\u258d                           | 62.6 MB 14.7 MB/s eta 0:00:27\ufffd\ufffd\u2588\u2588\u2588\u2588                      | 140.6 MB 81.3 MB/s eta 0:00:04     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 233.2 MB 79.7 MB/s eta 0:00:03\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           | 297.8 MB 85.8 MB/s eta 0:00:02\n\u001b[?25hCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.8 MB 72.2 MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor~=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 462 kB 66.5 MB/s eta 0:00:01\n\u001b[?25hCollecting astunparse~=1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting protobuf>=3.9.2\n  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.0 MB 55.4 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-preprocessing~=1.1.2\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 1.2 MB/s  eta 0:00:01\n\u001b[?25hCollecting grpcio~=1.34.0\n  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.0 MB 69.0 MB/s eta 0:00:01\n\u001b[?25hCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.0 MB 75.5 MB/s eta 0:00:01\n\u001b[?25hCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting google-pasta~=0.2\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 57 kB 5.1 MB/s  eta 0:00:01\n\u001b[?25hCollecting absl-py~=0.10\n  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 132 kB 79.3 MB/s eta 0:00:01\n\u001b[?25hCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nCollecting six~=1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting keras-nightly~=2.5.0.dev\n  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.2 MB 66.0 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard~=2.5\n  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.0 MB 76.8 MB/s eta 0:00:01\n\u001b[?25hCollecting opt-einsum~=3.3.0\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 65 kB 3.9 MB/s  eta 0:00:01\n\u001b[?25hCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting typing-extensions~=3.7.4\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting gast==0.4.0\n  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nCollecting cached-property; python_version < \"3.8\"\n  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 97 kB 7.3 MB/s  eta 0:00:01\n\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.9 MB 33.8 MB/s eta 0:00:01\n\u001b[?25hCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 288 kB 76.6 MB/s eta 0:00:01\n\u001b[?25hCollecting requests<3,>=2.21.0\n  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61 kB 9.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.31.0-py2.py3-none-any.whl (147 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 147 kB 65.5 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 781 kB 41.1 MB/s eta 0:00:01\n\u001b[?25hCollecting setuptools>=41.0.0\n  Downloading setuptools-57.0.0-py3-none-any.whl (821 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 821 kB 62.2 MB/s eta 0:00:01\n\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\nCollecting importlib-metadata; python_version < \"3.8\"\n  Downloading importlib_metadata-4.5.0-py3-none-any.whl (17 kB)\nCollecting idna<3,>=2.5\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 58 kB 6.3 MB/s  eta 0:00:01\n\u001b[?25hCollecting chardet<5,>=3.0.2\n  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178 kB 79.7 MB/s eta 0:00:01\n\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 138 kB 73.1 MB/s eta 0:00:01\n\u001b[?25hCollecting certifi>=2017.4.17\n  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 145 kB 72.7 MB/s eta 0:00:01\n\u001b[?25hCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 155 kB 74.1 MB/s eta 0:00:01\n\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\nCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\nCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\nCollecting pyasn1<0.5.0,>=0.4.6\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 77 kB 6.1 MB/s  eta 0:00:01\n\u001b[?25hCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 146 kB 60.6 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=6ea8c312adfc9752c4ed4864df10bafd43bb4042e948fa062060420189ebafe3\n  Stored in directory: /home/spark/shared/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=76682 sha256=7214ee097e5f4d023b62200e824a2af8d8423172313b5db84efe37a15c15dcc3\n  Stored in directory: /home/spark/shared/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built termcolor wrapt\n\u001b[31mERROR: conda 4.8.2 requires ruamel_yaml>=0.11.14, which is not installed.\u001b[0m\n\u001b[31mERROR: botocore 1.16.11 has requirement urllib3<1.26,>=1.20, but you'll have urllib3 1.26.5 which is incompatible.\u001b[0m\n\u001b[31mERROR: aiohttp 3.6.2 has requirement chardet<4.0,>=2.0, but you'll have chardet 4.0.0 which is incompatible.\u001b[0m\nInstalling collected packages: numpy, termcolor, tensorflow-estimator, six, wheel, astunparse, protobuf, keras-preprocessing, grpcio, cached-property, h5py, google-pasta, absl-py, flatbuffers, keras-nightly, typing-extensions, zipp, importlib-metadata, markdown, tensorboard-data-server, werkzeug, idna, chardet, urllib3, certifi, requests, pyasn1, pyasn1-modules, setuptools, rsa, cachetools, google-auth, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, opt-einsum, wrapt, gast, tensorflow\nSuccessfully installed absl-py-0.13.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.2 certifi-2021.5.30 chardet-4.0.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.31.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-2.10 importlib-metadata-4.5.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 setuptools-57.0.0 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.5 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\nCollecting python-mnist\n  Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\nInstalling collected packages: python-mnist\nSuccessfully installed python-mnist-0.7\n\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/bin already exists. Specify --upgrade to force replacement.\u001b[0m\nCollecting Pillow\n  Downloading Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.0 MB 18.0 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: Pillow\nSuccessfully installed Pillow-8.2.0\nCollecting pyspark\n  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 212.4 MB 145 kB/s  eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.9\n  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 198 kB 5.0 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=3cc217b08e7748b32d115542af3f8c58c1612401026c810c4cb000df34c5a917\n  Stored in directory: /home/spark/shared/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\nSuccessfully built pyspark\n\u001b[31mERROR: sparktspy-nojars 2.0.5.0 has requirement pyspark==3.0.1, but you'll have pyspark 3.1.2 which is incompatible.\u001b[0m\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9 pyspark-3.1.2\n\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
                }
            ],
            "source": "!pip install tensorflow\n!pip install python-mnist\n!pip install Pillow\n!pip install pyspark"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'2.5.0'"
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\nimport tensorflow as tf\nimport seaborn as sns\nfrom mnist import MNIST\nimport numpy as np\nimport PIL\nfrom PIL import Image\nimport os\nimport matplotlib.image as mping\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer\nfrom numpy import asarray\nimport pandas as pd\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import backend as K\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA\n\ntf.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'8.2.0'"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "PIL.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "# fire up the spark session\n# comment this cell out for a spark server\n#sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\n#spark = SparkSession \\\n#    .builder \\\n#    .getOrCreate()"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "# enable arrow which lets us transfrom a pandas dataframe into a pyspark dataframe\nspark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## First dataset\n\n#### 60,000 images and 10 classes, each image is 28 x 28 or represented by a 794 element array"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-06-16 23:10:26--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 18165135 (17M)\nSaving to: \u2018train-images-idx3-ubyte.gz?raw=True\u2019\n\ntrain-images-idx3-u 100%[===================>]  17.32M  6.27MB/s    in 2.8s    \n\n2021-06-16 23:10:30 (6.27 MB/s) - \u2018train-images-idx3-ubyte.gz?raw=True\u2019 saved [18165135/18165135]\n\n-rw-rw-r-- 1 spark spark 45M Feb  4  2019 train-images-idx3-ubyte\n--2021-06-16 23:10:33--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 29497 (29K)\nSaving to: \u2018train-labels-idx1-ubyte.gz?raw=True\u2019\n\ntrain-labels-idx1-u 100%[===================>]  28.81K  --.-KB/s    in 0.1s    \n\n2021-06-16 23:10:33 (200 KB/s) - \u2018train-labels-idx1-ubyte.gz?raw=True\u2019 saved [29497/29497]\n\n-rw-rw-r-- 1 spark spark 59K Feb  4  2019 train-labels-idx1-ubyte\n--2021-06-16 23:10:35--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3041136 (2.9M)\nSaving to: \u2018t10k-images-idx3-ubyte.gz?raw=True\u2019\n\nt10k-images-idx3-ub 100%[===================>]   2.90M  2.64MB/s    in 1.1s    \n\n2021-06-16 23:10:37 (2.64 MB/s) - \u2018t10k-images-idx3-ubyte.gz?raw=True\u2019 saved [3041136/3041136]\n\n-rw-rw-r-- 1 spark spark 7.5M Feb  4  2019 t10k-images-idx3-ubyte\n--2021-06-16 23:10:40--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5120 (5.0K)\nSaving to: \u2018t10k-labels-idx1-ubyte.gz?raw=True\u2019\n\nt10k-labels-idx1-ub 100%[===================>]   5.00K  --.-KB/s    in 0s      \n\n2021-06-16 23:10:40 (234 MB/s) - \u2018t10k-labels-idx1-ubyte.gz?raw=True\u2019 saved [5120/5120]\n\n-rw-rw-r-- 1 spark spark 9.8K Feb  4  2019 t10k-labels-idx1-ubyte\n"
                }
            ],
            "source": "!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz?raw=True\n!mv train-images-idx3-ubyte.gz?raw=True train-images-idx3-ubyte.gz\n!gunzip train-images-idx3-ubyte.gz\n!ls -lahr train-images-idx3-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz?raw=True\n!mv train-labels-idx1-ubyte.gz?raw=True train-labels-idx1-ubyte.gz\n!gunzip train-labels-idx1-ubyte.gz\n!ls -lahr train-labels-idx1-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz?raw=True\n!mv t10k-images-idx3-ubyte.gz?raw=True t10k-images-idx3-ubyte.gz\n!gunzip t10k-images-idx3-ubyte.gz\n!ls -lahr t10k-images-idx3-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz?raw=True\n!mv t10k-labels-idx1-ubyte.gz?raw=True t10k-labels-idx1-ubyte.gz\n!gunzip t10k-labels-idx1-ubyte.gz\n!ls -lahr t10k-labels-idx1-ubyte"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "total 53908\r\ndrwxrwxr-x  2 spark spark     4096 Jun 16 23:10 .\r\ndrwxr-xr-x 11 spark  2000     4096 Jun 16 23:10 ..\r\n-rw-rw-r--  1 spark spark  7840016 Jun 16 23:10 t10k-images-idx3-ubyte\r\n-rw-rw-r--  1 spark spark    10008 Jun 16 23:10 t10k-labels-idx1-ubyte\r\n-rw-rw-r--  1 spark spark 47040016 Jun 16 23:10 train-images-idx3-ubyte\r\n-rw-rw-r--  1 spark spark    60008 Jun 16 23:10 train-labels-idx1-ubyte\r\n"
                }
            ],
            "source": "!mkdir kmnistdata\n!cp t10k-images-idx3-ubyte kmnistdata/t10k-images-idx3-ubyte\n!cp t10k-labels-idx1-ubyte kmnistdata/t10k-labels-idx1-ubyte\n!cp train-images-idx3-ubyte kmnistdata/train-images-idx3-ubyte\n!cp train-labels-idx1-ubyte kmnistdata/train-labels-idx1-ubyte\n!ls -al kmnistdata\n\ndata = MNIST('kmnistdata')\ntrain_images, train_labels = data.load_training()\ntest_images, test_labels = data.load_testing()\n\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\n\ntrain_images = train_images / 255\ntest_images = test_images / 255"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "# model_1 def\n\nmodel_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_1 compile\nmodel_1.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4048 - accuracy: 0.8803 - val_loss: 0.5066 - val_accuracy: 0.8456\nEpoch 2/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.1947 - accuracy: 0.9426 - val_loss: 0.4295 - val_accuracy: 0.8718\nEpoch 3/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.1385 - accuracy: 0.9597 - val_loss: 0.3975 - val_accuracy: 0.8907\nEpoch 4/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.1047 - accuracy: 0.9696 - val_loss: 0.4275 - val_accuracy: 0.8801\nEpoch 5/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.0809 - accuracy: 0.9761 - val_loss: 0.3971 - val_accuracy: 0.8982\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fb78c0a2750>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1 fit\n\n# began by using 5 epochs here but observed that \n# the validation accuracy is increasing even as we\n# stopped training, so consider using more epochs here next\n\nmodel_1.fit(train_images, train_labels, epochs=5, verbose=1, validation_data=(test_images, test_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1 test loss: 0.3971461057662964\nmodel_1 test accuracy 0.8981999754905701\n"
                }
            ],
            "source": "score = model_1.evaluate(test_images, test_labels, verbose=0)\nprint('model_1 test loss:', score[0])\nprint('model_1 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_1 def\n\nmodel_1_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_1 compile\nmodel_1_1.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4807 - accuracy: 0.8521 - val_loss: 0.5372 - val_accuracy: 0.8344\nEpoch 2/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.2692 - accuracy: 0.9171 - val_loss: 0.4496 - val_accuracy: 0.8587\nEpoch 3/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9329 - val_loss: 0.4092 - val_accuracy: 0.8790\nEpoch 4/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.1801 - accuracy: 0.9444 - val_loss: 0.3915 - val_accuracy: 0.8871\nEpoch 5/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.1662 - accuracy: 0.9484 - val_loss: 0.3839 - val_accuracy: 0.8890\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f3b8c3a7c50>"
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_1 fit\nmodel_1_1.fit(train_images, train_labels, epochs=5, verbose=1, validation_data=(test_images, test_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_33 (Dense)             (None, 128)               100480    \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_34 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_35 (Dense)             (None, 10)                1290      \n=================================================================\nTotal params: 118,282\nTrainable params: 118,282\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "model_1_1.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2 def\n\nmodel_1_2 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2 compile\nmodel_1_2.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.3722 - accuracy: 0.8857 - val_loss: 0.5198 - val_accuracy: 0.8383\nEpoch 2/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1791 - accuracy: 0.9460 - val_loss: 0.4599 - val_accuracy: 0.8676\nEpoch 3/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1261 - accuracy: 0.9617 - val_loss: 0.4123 - val_accuracy: 0.8814\nEpoch 4/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1046 - accuracy: 0.9681 - val_loss: 0.4151 - val_accuracy: 0.8933\nEpoch 5/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9747 - val_loss: 0.4230 - val_accuracy: 0.8908\nEpoch 6/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0675 - accuracy: 0.9791 - val_loss: 0.4180 - val_accuracy: 0.8970\nEpoch 7/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.4154 - val_accuracy: 0.8987\nEpoch 8/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0523 - accuracy: 0.9837 - val_loss: 0.4947 - val_accuracy: 0.8912\nEpoch 9/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.4445 - val_accuracy: 0.8974\nEpoch 10/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 0.5009 - val_accuracy: 0.8985\nEpoch 11/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.4986 - val_accuracy: 0.9005\nEpoch 12/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.5347 - val_accuracy: 0.8962\nEpoch 13/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.5516 - val_accuracy: 0.9018\nEpoch 14/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 0.5276 - val_accuracy: 0.9038\nEpoch 15/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.5073 - val_accuracy: 0.9056\nEpoch 16/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.5310 - val_accuracy: 0.9074\nEpoch 17/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.5616 - val_accuracy: 0.9026\nEpoch 18/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.5574 - val_accuracy: 0.9090\nEpoch 19/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.6296 - val_accuracy: 0.9029\nEpoch 20/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.6076 - val_accuracy: 0.9082\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f3b6c554e10>"
                    },
                    "execution_count": 54,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_2 fit\nmodel_1_2.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(test_images, test_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_36 (Dense)             (None, 128)               100480    \n_________________________________________________________________\ndense_37 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_38 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_39 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_40 (Dense)             (None, 10)                1290      \n=================================================================\nTotal params: 151,306\nTrainable params: 151,306\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "model_1_2.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_3 def\n\nmodel_1_3 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_3 compile\nmodel_1_3.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.4513 - accuracy: 0.8613 - val_loss: 0.5261 - val_accuracy: 0.8399\nEpoch 2/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2188 - accuracy: 0.9348 - val_loss: 0.4477 - val_accuracy: 0.8650\nEpoch 3/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1648 - accuracy: 0.9506 - val_loss: 0.4268 - val_accuracy: 0.8837\nEpoch 4/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1326 - accuracy: 0.9604 - val_loss: 0.3916 - val_accuracy: 0.8929\nEpoch 5/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1138 - accuracy: 0.9666 - val_loss: 0.3983 - val_accuracy: 0.8895\nEpoch 6/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0943 - accuracy: 0.9714 - val_loss: 0.4388 - val_accuracy: 0.8899\nEpoch 7/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.4374 - val_accuracy: 0.8923\nEpoch 8/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0774 - accuracy: 0.9767 - val_loss: 0.4261 - val_accuracy: 0.8929\nEpoch 9/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.4281 - val_accuracy: 0.8980\nEpoch 10/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 0.4724 - val_accuracy: 0.8949\nEpoch 11/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0572 - accuracy: 0.9829 - val_loss: 0.4482 - val_accuracy: 0.9027\nEpoch 12/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0510 - accuracy: 0.9846 - val_loss: 0.4692 - val_accuracy: 0.9042\nEpoch 13/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0499 - accuracy: 0.9849 - val_loss: 0.5359 - val_accuracy: 0.8918\nEpoch 14/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 0.4440 - val_accuracy: 0.9007\nEpoch 15/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.5110 - val_accuracy: 0.9058\nEpoch 16/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.5444 - val_accuracy: 0.9010\nEpoch 17/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.5134 - val_accuracy: 0.9040\nEpoch 18/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.5336 - val_accuracy: 0.8990\nEpoch 19/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.5940 - val_accuracy: 0.8990\nEpoch 20/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 0.6163 - val_accuracy: 0.8973\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f3b6c6dec90>"
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_3 fit\nmodel_1_3.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(test_images, test_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_4 def\n\nmodel_1_4 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_4 compile\n\nmodel_1_4.compile(optimizer=tf.keras.optimizers.Adadelta(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1875/1875 [==============================] - 5s 3ms/step - loss: 2.2887 - accuracy: 0.1389 - val_loss: 2.2826 - val_accuracy: 0.1397\nEpoch 2/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.2387 - accuracy: 0.2098 - val_loss: 2.2480 - val_accuracy: 0.1768\nEpoch 3/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.1765 - accuracy: 0.2908 - val_loss: 2.2032 - val_accuracy: 0.2277\nEpoch 4/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.0938 - accuracy: 0.3853 - val_loss: 2.1450 - val_accuracy: 0.2882\nEpoch 5/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.9884 - accuracy: 0.4529 - val_loss: 2.0727 - val_accuracy: 0.3376\nEpoch 6/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.8645 - accuracy: 0.5017 - val_loss: 1.9919 - val_accuracy: 0.3773\nEpoch 7/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.7342 - accuracy: 0.5435 - val_loss: 1.9111 - val_accuracy: 0.4105\nEpoch 8/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.6090 - accuracy: 0.5814 - val_loss: 1.8350 - val_accuracy: 0.4467\nEpoch 9/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.4955 - accuracy: 0.6195 - val_loss: 1.7680 - val_accuracy: 0.4764\nEpoch 10/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.3955 - accuracy: 0.6489 - val_loss: 1.7075 - val_accuracy: 0.4958\nEpoch 11/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.3091 - accuracy: 0.6693 - val_loss: 1.6542 - val_accuracy: 0.5120\nEpoch 12/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.2341 - accuracy: 0.6838 - val_loss: 1.6048 - val_accuracy: 0.5242\nEpoch 13/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1688 - accuracy: 0.6944 - val_loss: 1.5617 - val_accuracy: 0.5323\nEpoch 14/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1123 - accuracy: 0.7027 - val_loss: 1.5190 - val_accuracy: 0.5401\nEpoch 15/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0628 - accuracy: 0.7106 - val_loss: 1.4837 - val_accuracy: 0.5479\nEpoch 16/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0198 - accuracy: 0.7178 - val_loss: 1.4493 - val_accuracy: 0.5571\nEpoch 17/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9816 - accuracy: 0.7244 - val_loss: 1.4182 - val_accuracy: 0.5667\nEpoch 18/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9480 - accuracy: 0.7317 - val_loss: 1.3857 - val_accuracy: 0.5752\nEpoch 19/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9178 - accuracy: 0.7390 - val_loss: 1.3616 - val_accuracy: 0.5834\nEpoch 20/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8906 - accuracy: 0.7456 - val_loss: 1.3349 - val_accuracy: 0.5905\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f3b6c3f87d0>"
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_4 fit\n\nmodel_1_4.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(test_images, test_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5 def\n\nmodel_1_5 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5 compile\n\nmodel_1_5.compile(optimizer='sgd',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.9446 - accuracy: 0.7149 - val_loss: 0.8656 - val_accuracy: 0.7227\nEpoch 2/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4174 - accuracy: 0.8721 - val_loss: 0.6876 - val_accuracy: 0.7840\nEpoch 3/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3243 - accuracy: 0.9013 - val_loss: 0.6232 - val_accuracy: 0.8074\nEpoch 4/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2668 - accuracy: 0.9203 - val_loss: 0.5939 - val_accuracy: 0.8173\nEpoch 5/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2259 - accuracy: 0.9320 - val_loss: 0.5436 - val_accuracy: 0.8390\nEpoch 6/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1958 - accuracy: 0.9427 - val_loss: 0.5060 - val_accuracy: 0.8485\nEpoch 7/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1698 - accuracy: 0.9505 - val_loss: 0.4889 - val_accuracy: 0.8544\nEpoch 8/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1493 - accuracy: 0.9557 - val_loss: 0.4861 - val_accuracy: 0.8551\nEpoch 9/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1316 - accuracy: 0.9611 - val_loss: 0.4982 - val_accuracy: 0.8576\nEpoch 10/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1163 - accuracy: 0.9651 - val_loss: 0.4720 - val_accuracy: 0.8610\nEpoch 11/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1039 - accuracy: 0.9694 - val_loss: 0.4492 - val_accuracy: 0.8764\nEpoch 12/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0923 - accuracy: 0.9735 - val_loss: 0.4679 - val_accuracy: 0.8724\nEpoch 13/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9767 - val_loss: 0.4561 - val_accuracy: 0.8786\nEpoch 14/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0712 - accuracy: 0.9801 - val_loss: 0.4690 - val_accuracy: 0.8754\nEpoch 15/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.4710 - val_accuracy: 0.8786\nEpoch 16/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0550 - accuracy: 0.9853 - val_loss: 0.4933 - val_accuracy: 0.8764\nEpoch 17/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0479 - accuracy: 0.9873 - val_loss: 0.4819 - val_accuracy: 0.8811\nEpoch 18/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0416 - accuracy: 0.9893 - val_loss: 0.5052 - val_accuracy: 0.8844\nEpoch 19/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.5249 - val_accuracy: 0.8793\nEpoch 20/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.5060 - val_accuracy: 0.8876\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f292876d990>"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_5 fit\n\nmodel_1_5.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(test_images, test_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "# model_2 def\n\n# optimizer is adam and loss is sparse_categorical_crossentropy\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\nx_train = train_images\nx_test = test_images\ny_train = train_labels\ny_test = test_labels\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nmodel_2 = tf.keras.Sequential()\nmodel_2.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(Dropout(0.25))\nmodel_2.add(tf.keras.layers.Flatten())\nmodel_2.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2.add(Dropout(0.5))\nmodel_2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\n# model_2 compile\n\nmodel_2.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n469/469 [==============================] - 211s 450ms/step - loss: 0.4129 - accuracy: 0.8742 - val_loss: 0.3417 - val_accuracy: 0.9001\nEpoch 2/12\n469/469 [==============================] - 209s 445ms/step - loss: 0.1737 - accuracy: 0.9475 - val_loss: 0.2736 - val_accuracy: 0.9198\nEpoch 3/12\n469/469 [==============================] - 208s 443ms/step - loss: 0.1290 - accuracy: 0.9598 - val_loss: 0.2315 - val_accuracy: 0.9371\nEpoch 4/12\n469/469 [==============================] - 209s 446ms/step - loss: 0.1016 - accuracy: 0.9682 - val_loss: 0.2087 - val_accuracy: 0.9409\nEpoch 5/12\n469/469 [==============================] - 208s 443ms/step - loss: 0.0820 - accuracy: 0.9740 - val_loss: 0.2093 - val_accuracy: 0.9436\nEpoch 6/12\n469/469 [==============================] - 208s 443ms/step - loss: 0.0701 - accuracy: 0.9777 - val_loss: 0.2163 - val_accuracy: 0.9427\nEpoch 7/12\n469/469 [==============================] - 208s 443ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.2089 - val_accuracy: 0.9478\nEpoch 8/12\n469/469 [==============================] - 208s 444ms/step - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.2130 - val_accuracy: 0.9489\nEpoch 9/12\n469/469 [==============================] - 208s 443ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.1924 - val_accuracy: 0.9526\nEpoch 10/12\n469/469 [==============================] - 208s 443ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 0.2268 - val_accuracy: 0.9472\nEpoch 11/12\n469/469 [==============================] - 200s 426ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.2108 - val_accuracy: 0.9530\nEpoch 12/12\n469/469 [==============================] - 197s 421ms/step - loss: 0.0372 - accuracy: 0.9871 - val_loss: 0.2121 - val_accuracy: 0.9539\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fe4603c49d0>"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model\n\nmodel_2.fit(x_train, y_train,\n         batch_size=batch_size,\n         epochs=epochs,\n         verbose=1,\n         validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_2_1: change of optimizer to Adadelta and compile\n\nmodel_2_1 = tf.keras.Sequential()\nmodel_2_1.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_1.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_1.add(Dropout(0.25))\nmodel_2_1.add(tf.keras.layers.Flatten())\nmodel_2_1.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_1.add(Dropout(0.5))\nmodel_2_1.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_1.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Adadelta',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n469/469 [==============================] - 95s 201ms/step - loss: 2.2868 - accuracy: 0.1344 - val_loss: 2.2696 - val_accuracy: 0.2132\nEpoch 2/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.2362 - accuracy: 0.2278 - val_loss: 2.2276 - val_accuracy: 0.3141\nEpoch 3/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.1717 - accuracy: 0.3177 - val_loss: 2.1737 - val_accuracy: 0.3703\nEpoch 4/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.0875 - accuracy: 0.3818 - val_loss: 2.1041 - val_accuracy: 0.4162\nEpoch 5/12\n469/469 [==============================] - 94s 200ms/step - loss: 1.9792 - accuracy: 0.4356 - val_loss: 2.0183 - val_accuracy: 0.4452\nEpoch 6/12\n469/469 [==============================] - 94s 201ms/step - loss: 1.8557 - accuracy: 0.4754 - val_loss: 1.9250 - val_accuracy: 0.4672\nEpoch 7/12\n469/469 [==============================] - 94s 200ms/step - loss: 1.7320 - accuracy: 0.5032 - val_loss: 1.8345 - val_accuracy: 0.4852\nEpoch 8/12\n469/469 [==============================] - 94s 201ms/step - loss: 1.6166 - accuracy: 0.5320 - val_loss: 1.7546 - val_accuracy: 0.5047\nEpoch 9/12\n469/469 [==============================] - 93s 199ms/step - loss: 1.5168 - accuracy: 0.5545 - val_loss: 1.6858 - val_accuracy: 0.5177\nEpoch 10/12\n469/469 [==============================] - 94s 200ms/step - loss: 1.4366 - accuracy: 0.5730 - val_loss: 1.6286 - val_accuracy: 0.5275\nEpoch 11/12\n469/469 [==============================] - 94s 201ms/step - loss: 1.3699 - accuracy: 0.5911 - val_loss: 1.5776 - val_accuracy: 0.5353\nEpoch 12/12\n469/469 [==============================] - 94s 201ms/step - loss: 1.3107 - accuracy: 0.6065 - val_loss: 1.5314 - val_accuracy: 0.5432\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f618c5b5750>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_1.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Adamax\n\n# model_2_2: change of optimizer to Adamax and compile\n\nmodel_2_2 = tf.keras.Sequential()\nmodel_2_2.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_2.add(Dropout(0.25))\nmodel_2_2.add(tf.keras.layers.Flatten())\nmodel_2_2.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_2.add(Dropout(0.5))\nmodel_2_2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_2.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Adamax',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n469/469 [==============================] - 95s 202ms/step - loss: 0.5973 - accuracy: 0.8165 - val_loss: 0.5072 - val_accuracy: 0.8421\nEpoch 2/12\n469/469 [==============================] - 93s 199ms/step - loss: 0.2788 - accuracy: 0.9162 - val_loss: 0.3876 - val_accuracy: 0.8847\nEpoch 3/12\n469/469 [==============================] - 94s 200ms/step - loss: 0.2121 - accuracy: 0.9376 - val_loss: 0.3238 - val_accuracy: 0.9056\nEpoch 4/12\n469/469 [==============================] - 93s 199ms/step - loss: 0.1723 - accuracy: 0.9477 - val_loss: 0.3036 - val_accuracy: 0.9139\nEpoch 5/12\n469/469 [==============================] - 94s 200ms/step - loss: 0.1514 - accuracy: 0.9544 - val_loss: 0.2632 - val_accuracy: 0.9246\nEpoch 6/12\n469/469 [==============================] - 94s 200ms/step - loss: 0.1321 - accuracy: 0.9598 - val_loss: 0.2511 - val_accuracy: 0.9304\nEpoch 7/12\n469/469 [==============================] - 93s 198ms/step - loss: 0.1150 - accuracy: 0.9647 - val_loss: 0.2460 - val_accuracy: 0.9293\nEpoch 8/12\n469/469 [==============================] - 93s 199ms/step - loss: 0.1053 - accuracy: 0.9676 - val_loss: 0.2406 - val_accuracy: 0.9351\nEpoch 9/12\n469/469 [==============================] - 93s 199ms/step - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.2287 - val_accuracy: 0.9390\nEpoch 10/12\n469/469 [==============================] - 93s 198ms/step - loss: 0.0885 - accuracy: 0.9720 - val_loss: 0.2302 - val_accuracy: 0.9392\nEpoch 11/12\n469/469 [==============================] - 93s 199ms/step - loss: 0.0829 - accuracy: 0.9743 - val_loss: 0.2284 - val_accuracy: 0.9391\nEpoch 12/12\n469/469 [==============================] - 93s 197ms/step - loss: 0.0761 - accuracy: 0.9758 - val_loss: 0.2371 - val_accuracy: 0.9387\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f618c5133d0>"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_2.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Adagrad\n\n# model_2_3: change of optimizer to Adagrad and compile\n\nmodel_2_3 = tf.keras.Sequential()\nmodel_2_3.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_3.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_3.add(Dropout(0.25))\nmodel_2_3.add(tf.keras.layers.Flatten())\nmodel_2_3.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_3.add(Dropout(0.5))\nmodel_2_3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_3.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Adagrad',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n109/469 [=====>........................] - ETA: 1:09 - loss: 2.2795 - accuracy: 0.1735"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-14-9cd75f4ff8f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m            validation_data=(x_test, y_test))\n\u001b[0m",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": "model_2_3.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Nadam\n\n# model_2_4: change of optimizer to Nadam and compile\n\nmodel_2_4 = tf.keras.Sequential()\nmodel_2_4.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_4.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_4.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_4.add(Dropout(0.25))\nmodel_2_4.add(tf.keras.layers.Flatten())\nmodel_2_4.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_4.add(Dropout(0.5))\nmodel_2_4.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_4.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Nadam',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n469/469 [==============================] - 97s 206ms/step - loss: 0.4006 - accuracy: 0.8765 - val_loss: 0.3753 - val_accuracy: 0.8869\nEpoch 2/12\n469/469 [==============================] - 95s 203ms/step - loss: 0.1686 - accuracy: 0.9496 - val_loss: 0.2696 - val_accuracy: 0.9219\nEpoch 3/12\n469/469 [==============================] - 95s 204ms/step - loss: 0.1271 - accuracy: 0.9604 - val_loss: 0.2380 - val_accuracy: 0.9340\nEpoch 4/12\n469/469 [==============================] - 96s 204ms/step - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.2271 - val_accuracy: 0.9407\nEpoch 5/12\n469/469 [==============================] - 96s 204ms/step - loss: 0.0836 - accuracy: 0.9736 - val_loss: 0.2184 - val_accuracy: 0.9427\nEpoch 6/12\n469/469 [==============================] - 96s 204ms/step - loss: 0.0676 - accuracy: 0.9787 - val_loss: 0.1975 - val_accuracy: 0.9490\nEpoch 7/12\n469/469 [==============================] - 96s 204ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.2283 - val_accuracy: 0.9439\nEpoch 8/12\n469/469 [==============================] - 95s 203ms/step - loss: 0.0541 - accuracy: 0.9819 - val_loss: 0.1975 - val_accuracy: 0.9522\nEpoch 9/12\n469/469 [==============================] - 96s 204ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 0.2026 - val_accuracy: 0.9545\nEpoch 10/12\n469/469 [==============================] - 95s 203ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 0.2121 - val_accuracy: 0.9550\nEpoch 11/12\n469/469 [==============================] - 96s 204ms/step - loss: 0.0388 - accuracy: 0.9871 - val_loss: 0.2211 - val_accuracy: 0.9544\nEpoch 12/12\n469/469 [==============================] - 96s 205ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.2240 - val_accuracy: 0.9539\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f61798bef50>"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_4.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Ftrl\n\n# model_2_5: change of optimizer to Ftrl and compile\n\nmodel_2_5 = tf.keras.Sequential()\nmodel_2_5.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_5.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_5.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_5.add(Dropout(0.25))\nmodel_2_5.add(tf.keras.layers.Flatten())\nmodel_2_5.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_5.add(Dropout(0.5))\nmodel_2_5.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_5.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Ftrl',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.3026 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 2/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.3026 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 3/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 4/12\n469/469 [==============================] - 94s 200ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 5/12\n469/469 [==============================] - 94s 201ms/step - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 6/12\n469/469 [==============================] - 93s 199ms/step - loss: 2.3026 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 7/12\n469/469 [==============================] - ETA: 0s - loss: 2.3026 - accuracy: 0.0991"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-19-f01b080ec55b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m            validation_data=(x_test, y_test))\n\u001b[0m",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": "model_2_5.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### This is the first dataset in .npz format"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-06-11 17:21:46--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 18384171 (18M)\nSaving to: \u2018kmnist-train-imgs.npz?raw=True\u2019\n\nkmnist-train-imgs.n 100%[===================>]  17.53M  4.25MB/s    in 4.9s    \n\n2021-06-11 17:21:52 (3.61 MB/s) - \u2018kmnist-train-imgs.npz?raw=True\u2019 saved [18384171/18384171]\n\n-rw-rw-r-- 1 spark spark 18M Feb  4  2019 kmnist-train-imgs.npz\n--2021-06-11 17:21:54--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 29700 (29K)\nSaving to: \u2018kmnist-train-labels.npz?raw=True\u2019\n\nkmnist-train-labels 100%[===================>]  29.00K  --.-KB/s    in 0.1s    \n\n2021-06-11 17:21:54 (211 KB/s) - \u2018kmnist-train-labels.npz?raw=True\u2019 saved [29700/29700]\n\n-rw-rw-r-- 1 spark spark 30K Feb  4  2019 kmnist-train-labels.npz\n--2021-06-11 17:21:56--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3079479 (2.9M)\nSaving to: \u2018kmnist-test-imgs.npz?raw=True\u2019\n\nkmnist-test-imgs.np 100%[===================>]   2.94M  2.30MB/s    in 1.3s    \n\n2021-06-11 17:21:58 (2.30 MB/s) - \u2018kmnist-test-imgs.npz?raw=True\u2019 saved [3079479/3079479]\n\n-rw-rw-r-- 1 spark spark 3.0M Feb  4  2019 kmnist-test-imgs.npz\n--2021-06-11 17:22:00--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5304 (5.2K)\nSaving to: \u2018kmnist-test-labels.npz?raw=True\u2019\n\nkmnist-test-labels. 100%[===================>]   5.18K  --.-KB/s    in 0s      \n\n2021-06-11 17:22:00 (137 MB/s) - \u2018kmnist-test-labels.npz?raw=True\u2019 saved [5304/5304]\n\n-rw-rw-r-- 1 spark spark 5.2K Feb  4  2019 kmnist-test-labels.npz\n"
                }
            ],
            "source": "!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz?raw=True\n!mv kmnist-train-imgs.npz?raw=True kmnist-train-imgs.npz\n!ls -lahr kmnist-train-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz?raw=True\n!mv kmnist-train-labels.npz?raw=True kmnist-train-labels.npz\n!ls -lahr kmnist-train-labels.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz?raw=True\n!mv kmnist-test-imgs.npz?raw=True kmnist-test-imgs.npz\n!ls -lahr kmnist-test-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz?raw=True\n!mv kmnist-test-labels.npz?raw=True kmnist-test-labels.npz\n!ls -lahr kmnist-test-labels.npz"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model:  K Nearest Neighbors"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "def load(f):\n    return np.load(f)['arr_0']"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "x_train = load('kmnist-train-imgs.npz')\ny_train = load('kmnist-train-labels.npz')\nx_test = load('kmnist-test-imgs.npz')\ny_test = load('kmnist-test-labels.npz')"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "x_train = x_train.reshape(-1, 784)\nx_test = x_test.reshape(-1, 784)"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fit KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n"
                },
                {
                    "data": {
                        "text/plain": "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_3 = KNeighborsClassifier(n_neighbors=4, weights='distance', n_jobs=-1)\nprint('Fit', model_3)\nmodel_3.fit(x_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Evaluate KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\nThe accuracy is: 0.921\n"
                }
            ],
            "source": "print('Evaluate', model_3)\nscore = model_3.score(x_test, y_test)\nprint('The accuracy is:', score)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model: K Nearest Neighbors with Principal Component Analysis dimensionality reduction"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# KNN with dim reduction:  the code is currently broken, skip this for now\n\npca = PCA(n_components=60, random_state=0)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "x_train = pca.fit_transform(x_train)\nx_test = pca.transform"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "model_4 = KNeighborsClassifier(n_neighbors=4, weights='distance', n_jobs=-1)\nprint('Fit', model_4)\nmodel_4.fit(x_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('Evaluate', model_4)\nscore = model_4.score(x_test, y_test)\nprint('The accuracy is:', score)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Second dataset\n\n#### 232,365 images, 49 classes, each image is 28 x 28 or represented by a 794 element array"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-06-15 00:36:01--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 66117696 (63M)\nSaving to: \u2018k49-train-imgs.npz?raw=True\u2019\n\nk49-train-imgs.npz? 100%[===================>]  63.05M  5.76MB/s    in 12s     \n\n2021-06-15 00:36:14 (5.34 MB/s) - \u2018k49-train-imgs.npz?raw=True\u2019 saved [66117696/66117696]\n\n-rw-rw-r-- 1 spark spark 64M Feb  4  2019 k49-train-imgs.npz\n--2021-06-15 00:36:16--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 164485 (161K)\nSaving to: \u2018k49-train-labels.npz?raw=True\u2019\n\nk49-train-labels.np 100%[===================>] 160.63K   376KB/s    in 0.4s    \n\n2021-06-15 00:36:17 (376 KB/s) - \u2018k49-train-labels.npz?raw=True\u2019 saved [164485/164485]\n\n-rw-rw-r-- 1 spark spark 161K Feb  4  2019 k49-train-labels.npz\n--2021-06-15 00:36:18--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10971201 (10M)\nSaving to: \u2018k49-test-imgs.npz?raw=True\u2019\n\nk49-test-imgs.npz?r 100%[===================>]  10.46M  1.76MB/s    in 6.5s    \n\n2021-06-15 00:36:25 (1.62 MB/s) - \u2018k49-test-imgs.npz?raw=True\u2019 saved [10971201/10971201]\n\n-rw-rw-r-- 1 spark spark 11M Feb  4  2019 k49-test-imgs.npz\n--2021-06-15 00:36:27--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 27450 (27K)\nSaving to: \u2018k49-test-labels.npz?raw=True\u2019\n\nk49-test-labels.npz 100%[===================>]  26.81K  --.-KB/s    in 0.1s    \n\n2021-06-15 00:36:27 (191 KB/s) - \u2018k49-test-labels.npz?raw=True\u2019 saved [27450/27450]\n\n-rw-rw-r-- 1 spark spark 27K Feb  4  2019 k49-test-labels.npz\n"
                }
            ],
            "source": "# download the train and test labels and images, \n# which are available onlyh in .npz format \n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz?raw=True\n!mv k49-train-imgs.npz?raw=True k49-train-imgs.npz\n!ls -lahr k49-train-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz?raw=True\n!mv k49-train-labels.npz?raw=True k49-train-labels.npz\n!ls -lahr k49-train-labels.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz?raw=True\n!mv k49-test-imgs.npz?raw=True k49-test-imgs.npz\n!ls -lahr k49-test-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz?raw=True\n!mv k49-test-labels.npz?raw=True k49-test-labels.npz\n!ls -lahr k49-test-labels.npz"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "def load(f):\n    return np.load(f)['arr_0']"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "x_train_k49 = load('k49-train-imgs.npz')\ny_train_k49 = load('k49-train-labels.npz')\nx_test_k49 = load('k49-test-imgs.npz')\ny_test_k49 = load('k49-test-labels.npz')\n\nx_train_k49 = x_train_k49.reshape(-1, 784)\nx_test_k49 = x_test_k49.reshape(-1, 784)\n\n\n# the numpy arrays used in the keras models need to be between 0 and 1\n# we keep x_train_k49 and x_test_k49 in the format of between 0 and 255\n# for use in the K-nearest Neighbors model below\n\ntrain_images_k49 = x_train_k49 / 255\ntest_images_k49 = x_test_k49 / 255\n\n# and the labels can be the same\n\ntrain_labels_k49 = y_train_k49\ntest_labels_k49 = y_test_k49"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_k49 def\n# we have to change the last layer due to the 49 categories\n\nmodel_1_k49 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(49, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_k49 compile\nmodel_1_k49.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/5\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.9142 - accuracy: 0.7662 - val_loss: 1.0799 - val_accuracy: 0.7278\nEpoch 2/5\n7262/7262 [==============================] - 13s 2ms/step - loss: 0.5710 - accuracy: 0.8474 - val_loss: 0.9618 - val_accuracy: 0.7581\nEpoch 3/5\n7262/7262 [==============================] - 13s 2ms/step - loss: 0.4910 - accuracy: 0.8670 - val_loss: 0.9151 - val_accuracy: 0.7734\nEpoch 4/5\n7262/7262 [==============================] - 13s 2ms/step - loss: 0.4495 - accuracy: 0.8786 - val_loss: 0.9089 - val_accuracy: 0.7800\nEpoch 5/5\n7262/7262 [==============================] - 13s 2ms/step - loss: 0.4226 - accuracy: 0.8843 - val_loss: 0.9129 - val_accuracy: 0.7817\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f57e44ea090>"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_k49 fit\n# as in the first data set, this model could probably use more epochs\nmodel_1_k49.fit(train_images_k49, train_labels_k49, epochs=5, verbose=1, validation_data=(test_images_k49, test_labels_k49))"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2_k49 def\n\nmodel_1_2_k49 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(49, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2_k49 compile\nmodel_1_2_k49.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n7262/7262 [==============================] - 17s 2ms/step - loss: 0.8359 - accuracy: 0.7735 - val_loss: 0.9507 - val_accuracy: 0.7440\nEpoch 2/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.5021 - accuracy: 0.8600 - val_loss: 0.8355 - val_accuracy: 0.7785\nEpoch 3/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.4239 - accuracy: 0.8810 - val_loss: 0.7762 - val_accuracy: 0.7992\nEpoch 4/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.3812 - accuracy: 0.8923 - val_loss: 0.7687 - val_accuracy: 0.8008\nEpoch 5/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.3527 - accuracy: 0.8997 - val_loss: 0.7548 - val_accuracy: 0.8121\nEpoch 6/20\n7262/7262 [==============================] - 17s 2ms/step - loss: 0.3314 - accuracy: 0.9058 - val_loss: 0.7723 - val_accuracy: 0.8113\nEpoch 7/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.3148 - accuracy: 0.9100 - val_loss: 0.7624 - val_accuracy: 0.8165\nEpoch 8/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.3027 - accuracy: 0.9132 - val_loss: 0.7623 - val_accuracy: 0.8148\nEpoch 9/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2923 - accuracy: 0.9156 - val_loss: 0.7801 - val_accuracy: 0.8182\nEpoch 10/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2821 - accuracy: 0.9185 - val_loss: 0.7877 - val_accuracy: 0.8138\nEpoch 11/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2739 - accuracy: 0.9213 - val_loss: 0.8045 - val_accuracy: 0.8211\nEpoch 12/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2675 - accuracy: 0.9230 - val_loss: 0.8105 - val_accuracy: 0.8241\nEpoch 13/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2633 - accuracy: 0.9245 - val_loss: 0.8031 - val_accuracy: 0.8240\nEpoch 14/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2584 - accuracy: 0.9253 - val_loss: 0.8457 - val_accuracy: 0.8230\nEpoch 15/20\n7262/7262 [==============================] - 17s 2ms/step - loss: 0.2520 - accuracy: 0.9272 - val_loss: 0.8306 - val_accuracy: 0.8210\nEpoch 16/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2513 - accuracy: 0.9280 - val_loss: 0.9010 - val_accuracy: 0.8178\nEpoch 17/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2468 - accuracy: 0.9295 - val_loss: 0.8909 - val_accuracy: 0.8162\nEpoch 18/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2425 - accuracy: 0.9305 - val_loss: 0.8849 - val_accuracy: 0.8216\nEpoch 19/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2381 - accuracy: 0.9321 - val_loss: 0.9081 - val_accuracy: 0.8242\nEpoch 20/20\n7262/7262 [==============================] - 16s 2ms/step - loss: 0.2347 - accuracy: 0.9336 - val_loss: 0.9067 - val_accuracy: 0.8215\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f65fd302650>"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_2_k49 fit\nmodel_1_2_k49.fit(train_images_k49, train_labels_k49, epochs=20, verbose=1, validation_data=(test_images_k49, test_labels_k49))"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 128)               100480    \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_4 (Dense)              (None, 49)                6321      \n=================================================================\nTotal params: 156,337\nTrainable params: 156,337\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "model_1_2_k49.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5_k49 def\n\nmodel_1_5_k49 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(49, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5_k49 compile\n\nmodel_1_5_k49.compile(optimizer='sgd',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n7262/7262 [==============================] - 15s 2ms/step - loss: 1.7135 - accuracy: 0.5690 - val_loss: 1.5775 - val_accuracy: 0.6086\nEpoch 2/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.8724 - accuracy: 0.7705 - val_loss: 1.2330 - val_accuracy: 0.6849\nEpoch 3/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.6760 - accuracy: 0.8188 - val_loss: 1.0666 - val_accuracy: 0.7251\nEpoch 4/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.5714 - accuracy: 0.8449 - val_loss: 0.9663 - val_accuracy: 0.7480\nEpoch 5/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.5047 - accuracy: 0.8612 - val_loss: 0.8925 - val_accuracy: 0.7698\nEpoch 6/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.4553 - accuracy: 0.8747 - val_loss: 0.8496 - val_accuracy: 0.7793\nEpoch 7/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.4175 - accuracy: 0.8841 - val_loss: 0.8400 - val_accuracy: 0.7818\nEpoch 8/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.3871 - accuracy: 0.8919 - val_loss: 0.8328 - val_accuracy: 0.7877\nEpoch 9/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.3613 - accuracy: 0.8989 - val_loss: 0.7757 - val_accuracy: 0.7993\nEpoch 10/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.3407 - accuracy: 0.9042 - val_loss: 0.7588 - val_accuracy: 0.8054\nEpoch 11/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.3219 - accuracy: 0.9098 - val_loss: 0.7452 - val_accuracy: 0.8108\nEpoch 12/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.3041 - accuracy: 0.9138 - val_loss: 0.7314 - val_accuracy: 0.8141\nEpoch 13/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2898 - accuracy: 0.9179 - val_loss: 0.7356 - val_accuracy: 0.8138\nEpoch 14/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2767 - accuracy: 0.9211 - val_loss: 0.7151 - val_accuracy: 0.8225\nEpoch 15/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2646 - accuracy: 0.9247 - val_loss: 0.7086 - val_accuracy: 0.8245\nEpoch 16/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2540 - accuracy: 0.9278 - val_loss: 0.7011 - val_accuracy: 0.8257\nEpoch 17/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2440 - accuracy: 0.9301 - val_loss: 0.7067 - val_accuracy: 0.8260\nEpoch 18/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2343 - accuracy: 0.9324 - val_loss: 0.7352 - val_accuracy: 0.8214\nEpoch 19/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2254 - accuracy: 0.9346 - val_loss: 0.6968 - val_accuracy: 0.8311\nEpoch 20/20\n7262/7262 [==============================] - 14s 2ms/step - loss: 0.2177 - accuracy: 0.9369 - val_loss: 0.7056 - val_accuracy: 0.8291\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7ff0000e0dd0>"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_5_k49 fit\n\nmodel_1_5_k49.fit(train_images_k49, train_labels_k49, epochs=20, verbose=1, validation_data=(test_images_k49, test_labels_k49))"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 128)               100480    \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_4 (Dense)              (None, 49)                6321      \n=================================================================\nTotal params: 156,337\nTrainable params: 156,337\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "# model_1_5_k49 fit\n\nmodel_1_5_k49.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "# model_2_k49 def\n\nbatch_size = 128\nnum_classes = 49       #  here we specify the number of classes as 49 instead of 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\nx_train = train_images_k49\nx_test = test_images_k49\ny_train = train_labels_k49\ny_test = test_labels_k49\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nmodel_2_k49 = tf.keras.Sequential()\nmodel_2_k49.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_k49.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_k49.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_k49.add(Dropout(0.25))\nmodel_2_k49.add(tf.keras.layers.Flatten())\nmodel_2_k49.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_k49.add(Dropout(0.5))\nmodel_2_k49.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\n# model_2 compile\n\nmodel_2_k49.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n1816/1816 [==============================] - 342s 188ms/step - loss: 0.9383 - accuracy: 0.7530 - val_loss: 0.6622 - val_accuracy: 0.8259\nEpoch 2/12\n1816/1816 [==============================] - 340s 187ms/step - loss: 0.5146 - accuracy: 0.8584 - val_loss: 0.5186 - val_accuracy: 0.8644\nEpoch 3/12\n1816/1816 [==============================] - 338s 186ms/step - loss: 0.4178 - accuracy: 0.8831 - val_loss: 0.4378 - val_accuracy: 0.8841\nEpoch 4/12\n1816/1816 [==============================] - 338s 186ms/step - loss: 0.3619 - accuracy: 0.8981 - val_loss: 0.3942 - val_accuracy: 0.8978\nEpoch 5/12\n1816/1816 [==============================] - 336s 185ms/step - loss: 0.3248 - accuracy: 0.9068 - val_loss: 0.3849 - val_accuracy: 0.9000\nEpoch 6/12\n1816/1816 [==============================] - 336s 185ms/step - loss: 0.2997 - accuracy: 0.9139 - val_loss: 0.3704 - val_accuracy: 0.9067\nEpoch 7/12\n1816/1816 [==============================] - 335s 185ms/step - loss: 0.2788 - accuracy: 0.9189 - val_loss: 0.3439 - val_accuracy: 0.9128\nEpoch 8/12\n1816/1816 [==============================] - 337s 185ms/step - loss: 0.2621 - accuracy: 0.9229 - val_loss: 0.3515 - val_accuracy: 0.9116\nEpoch 9/12\n1816/1816 [==============================] - 336s 185ms/step - loss: 0.2471 - accuracy: 0.9263 - val_loss: 0.3394 - val_accuracy: 0.9164\nEpoch 10/12\n1816/1816 [==============================] - 336s 185ms/step - loss: 0.2368 - accuracy: 0.9292 - val_loss: 0.3411 - val_accuracy: 0.9184\nEpoch 11/12\n1816/1816 [==============================] - 337s 186ms/step - loss: 0.2258 - accuracy: 0.9320 - val_loss: 0.3343 - val_accuracy: 0.9181\nEpoch 12/12\n1816/1816 [==============================] - 337s 186ms/step - loss: 0.2165 - accuracy: 0.9347 - val_loss: 0.3265 - val_accuracy: 0.9195\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f57cc4be750>"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model2_k49\n\nmodel_2_k49.fit(x_train, y_train,\n         batch_size=batch_size,\n         epochs=epochs,\n         verbose=1,\n         validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "# change of optimizer and compile model_2_k49\n\nmodel_2_k49.compile(loss='sparse_categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adadelta(),\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n1816/1816 [==============================] - 342s 188ms/step - loss: 0.1990 - accuracy: 0.9387 - val_loss: 0.3261 - val_accuracy: 0.9198\nEpoch 2/12\n1816/1816 [==============================] - 341s 188ms/step - loss: 0.1954 - accuracy: 0.9403 - val_loss: 0.3262 - val_accuracy: 0.9198\nEpoch 3/12\n1816/1816 [==============================] - 340s 188ms/step - loss: 0.1942 - accuracy: 0.9404 - val_loss: 0.3263 - val_accuracy: 0.9200\nEpoch 4/12\n1816/1816 [==============================] - 342s 188ms/step - loss: 0.1948 - accuracy: 0.9405 - val_loss: 0.3264 - val_accuracy: 0.9202\nEpoch 5/12\n1816/1816 [==============================] - 340s 187ms/step - loss: 0.1921 - accuracy: 0.9413 - val_loss: 0.3267 - val_accuracy: 0.9203\nEpoch 6/12\n1816/1816 [==============================] - 340s 187ms/step - loss: 0.1917 - accuracy: 0.9410 - val_loss: 0.3269 - val_accuracy: 0.9201\nEpoch 7/12\n1816/1816 [==============================] - 344s 189ms/step - loss: 0.1923 - accuracy: 0.9409 - val_loss: 0.3269 - val_accuracy: 0.9201\nEpoch 8/12\n1816/1816 [==============================] - 344s 190ms/step - loss: 0.1904 - accuracy: 0.9414 - val_loss: 0.3271 - val_accuracy: 0.9203\nEpoch 9/12\n1816/1816 [==============================] - 344s 189ms/step - loss: 0.1891 - accuracy: 0.9420 - val_loss: 0.3272 - val_accuracy: 0.9204\nEpoch 10/12\n1816/1816 [==============================] - 343s 189ms/step - loss: 0.1887 - accuracy: 0.9420 - val_loss: 0.3273 - val_accuracy: 0.9205\nEpoch 11/12\n1816/1816 [==============================] - 347s 191ms/step - loss: 0.1893 - accuracy: 0.9420 - val_loss: 0.3274 - val_accuracy: 0.9206\nEpoch 12/12\n1816/1816 [==============================] - 354s 195ms/step - loss: 0.1881 - accuracy: 0.9420 - val_loss: 0.3275 - val_accuracy: 0.9207\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f57cc363cd0>"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model_2_k49 after change of optmizer\n\nmodel_2_k49.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model:  K Nearest Neighbors - k49"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "# recall that the two numpy image arrays used below, namely x_train_k49 and x_test_k49\n# are arrays of integers, which works fine for KNN"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fit KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n"
                },
                {
                    "data": {
                        "text/plain": "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_3_k49 = KNeighborsClassifier(n_neighbors=4, weights='distance', n_jobs=-1)\nprint('Fit', model_3_k49)\nmodel_3_k49.fit(x_train_k49, y_train_k49)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Evaluate KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n"
                }
            ],
            "source": "print('Evaluate', model_3_k49)\nscore = model_3_k49.score(x_test_k49, y_test_k49)\nprint('The accuracy is:', score)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7 with Spark",
            "language": "python3",
            "name": "python37"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}