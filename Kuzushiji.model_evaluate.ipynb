{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "### Model Evaluation\n\nModel evaluation is a critical task in data science. This is one of the few measures business stakeholders are interested in. Model performance heavily influences business impact of a data science project. Therefore, it is important to take some time apart in an independent task in the process model. \n\nSo how are models evaluated? In supervised machine learning this is relatively straightforward since you can always create a ground truth and compare your results against ground truth.\n\nSo, we are either splitting data into training-, test- and validation-sets to assess model performance on the test set or we use cross validation. This all is explained in the following coursera course https://www.coursera.org/learn/advanced-machine-learning-signal-processing/ Week 2.\n\nIn case we know what data set we can use as ground truth in supervised learning (classification and regression) we need to define a different measure for evaluation than in unsupervised learning (clustering). Since it depends on the type of model we create, the following none exhaustive lists can be used as a starting point for further research:\n\n#### Classification:\n\n- Confusion Matrix\n\n- Accuracy\n\n- Precision\n\n- Recall\n\n- Specificity\n\n- True positive rate\n\n- True negative rate\n\n- False positive rate\n\n- False negative rate\n\n- F1-score\n\n- Gain and Lift\n\n- Kolomogorov Smirnov\n\n- Area Under ROC\n\n- Gini Coefficient\n\n- Concordant \u2013 Discordant ratio\n\n#### Regression:\n\n- Root Mean Squared Error (RMSE)\n\n- Mean Squared Error\n\n- Mean Absolute Error (MAE)\n\n- R-Squared\n\n- Relative Squared Error\n\n- Relative Absolute Error\n\n- Sum of Differences\n\n- ACF plot of residuals\n\n- Histogram of residuals\n\n- Residual plots against predictors\n\n- Residual plots against fitted values\n\nClustering:\n\n- Adjusted Rand index\n\n- Mutual Information\n\n- Homogeneity completeness\n\n- V-measure\n\n- Fowlkes-Mallows\n\n- Silhouette Coefficient Calinski-Harabaz\u00b6\n\nReferences:\n\nhttp://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n\nPlease choose at least one appropriate model performance measure, justify why you\u2019ve used it and document how iterative changes in the feature creation task influence it."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: tensorflow in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (2.4.1)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (3.11.2)\nRequirement already satisfied: h5py~=2.10.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (2.10.0)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (1.19.2)\nCollecting opt-einsum~=3.3.0\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 65 kB 7.6 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (0.35.1)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (0.10.0)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (0.3.3)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (2.4.0)\nCollecting keras-preprocessing~=1.1.2\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 3.2 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (2.4.1)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (1.6.3)\nCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorflow) (3.7.4.2)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.8 MB 24.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (47.3.1.post20200622)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.23.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.6.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (3.1.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.4.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.22.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.16.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.1)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2021.5.30)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\nInstalling collected packages: opt-einsum, keras-preprocessing, flatbuffers, grpcio\n  Attempting uninstall: opt-einsum\n    Found existing installation: opt-einsum 3.1.0\n    Uninstalling opt-einsum-3.1.0:\n      Successfully uninstalled opt-einsum-3.1.0\n  Attempting uninstall: keras-preprocessing\n    Found existing installation: Keras-Preprocessing 1.1.0\n    Uninstalling Keras-Preprocessing-1.1.0:\n      Successfully uninstalled Keras-Preprocessing-1.1.0\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 20210226132247\n    Uninstalling flatbuffers-20210226132247:\n      Successfully uninstalled flatbuffers-20210226132247\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.31.0\n    Uninstalling grpcio-1.31.0:\n      Successfully uninstalled grpcio-1.31.0\nSuccessfully installed flatbuffers-1.12 grpcio-1.32.0 keras-preprocessing-1.1.2 opt-einsum-3.3.0\nCollecting python-mnist\n  Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\nInstalling collected packages: python-mnist\nSuccessfully installed python-mnist-0.7\nRequirement already satisfied: Pillow in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (8.2.0)\nCollecting pyspark\n  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 212.4 MB 98.2 MB/s eta 0:00:011\n\u001b[?25hCollecting py4j==0.10.9\n  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 198 kB 38.0 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=5bdfebf233bb28657fe131c9407630b7f52f49adc9ce534f64627092328185dd\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9 pyspark-3.1.2\nRequirement already satisfied: scikit-learn in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (0.23.2)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from scikit-learn) (1.19.2)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from scikit-learn) (0.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n"
                }
            ],
            "source": "!pip install tensorflow\n!pip install python-mnist\n!pip install Pillow\n!pip install pyspark\n!pip install scikit-learn"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'2.4.1'"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\nimport tensorflow as tf\nimport seaborn as sns\nfrom mnist import MNIST\nimport numpy as np\nimport PIL\nfrom PIL import Image\nimport os\nimport matplotlib.image as mping\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer\nfrom numpy import asarray\nimport pandas as pd\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import backend as K\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA\n\ntf.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'8.2.0'"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "PIL.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "# fire up the spark session\n# comment this cell out for a spark server\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "# enable arrow which lets us transfrom a pandas dataframe into a pyspark dataframe\nspark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## First dataset\n\n#### 60,000 images and 10 classes, each image is 28 x 28 or represented by a 794 element array"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-07-06 21:06:22--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 18165135 (17M)\nSaving to: \u2018train-images-idx3-ubyte.gz?raw=True\u2019\n\ntrain-images-idx3-u 100%[===================>]  17.32M  6.12MB/s    in 2.8s    \n\n2021-07-06 21:06:26 (6.12 MB/s) - \u2018train-images-idx3-ubyte.gz?raw=True\u2019 saved [18165135/18165135]\n\n-rw-rw---- 1 wsuser watsonstudio 45M Feb  4  2019 train-images-idx3-ubyte\n--2021-07-06 21:06:28--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 29497 (29K)\nSaving to: \u2018train-labels-idx1-ubyte.gz?raw=True\u2019\n\ntrain-labels-idx1-u 100%[===================>]  28.81K  --.-KB/s    in 0.1s    \n\n2021-07-06 21:06:29 (203 KB/s) - \u2018train-labels-idx1-ubyte.gz?raw=True\u2019 saved [29497/29497]\n\n-rw-rw---- 1 wsuser watsonstudio 59K Feb  4  2019 train-labels-idx1-ubyte\n--2021-07-06 21:06:31--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3041136 (2.9M)\nSaving to: \u2018t10k-images-idx3-ubyte.gz?raw=True\u2019\n\nt10k-images-idx3-ub 100%[===================>]   2.90M  2.66MB/s    in 1.1s    \n\n2021-07-06 21:06:33 (2.66 MB/s) - \u2018t10k-images-idx3-ubyte.gz?raw=True\u2019 saved [3041136/3041136]\n\n-rw-rw---- 1 wsuser watsonstudio 7.5M Feb  4  2019 t10k-images-idx3-ubyte\n--2021-07-06 21:06:35--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5120 (5.0K)\nSaving to: \u2018t10k-labels-idx1-ubyte.gz?raw=True\u2019\n\nt10k-labels-idx1-ub 100%[===================>]   5.00K  --.-KB/s    in 0s      \n\n2021-07-06 21:06:38 (234 MB/s) - \u2018t10k-labels-idx1-ubyte.gz?raw=True\u2019 saved [5120/5120]\n\n-rw-rw---- 1 wsuser watsonstudio 9.8K Feb  4  2019 t10k-labels-idx1-ubyte\n"
                }
            ],
            "source": "!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz?raw=True\n!mv train-images-idx3-ubyte.gz?raw=True train-images-idx3-ubyte.gz\n!gunzip train-images-idx3-ubyte.gz\n!ls -lahr train-images-idx3-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz?raw=True\n!mv train-labels-idx1-ubyte.gz?raw=True train-labels-idx1-ubyte.gz\n!gunzip train-labels-idx1-ubyte.gz\n!ls -lahr train-labels-idx1-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz?raw=True\n!mv t10k-images-idx3-ubyte.gz?raw=True t10k-images-idx3-ubyte.gz\n!gunzip t10k-images-idx3-ubyte.gz\n!ls -lahr t10k-images-idx3-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz?raw=True\n!mv t10k-labels-idx1-ubyte.gz?raw=True t10k-labels-idx1-ubyte.gz\n!gunzip t10k-labels-idx1-ubyte.gz\n!ls -lahr t10k-labels-idx1-ubyte"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "total 53680\r\ndrwxrwx--- 2 wsuser watsonstudio     4096 Jul  6 21:06 .\r\ndrwxr-x--- 4 wsuser watsonstudio     4096 Jul  6 21:06 ..\r\n-rw-rw---- 1 wsuser watsonstudio  7840016 Jul  6 21:06 t10k-images-idx3-ubyte\r\n-rw-rw---- 1 wsuser watsonstudio    10008 Jul  6 21:06 t10k-labels-idx1-ubyte\r\n-rw-rw---- 1 wsuser watsonstudio 47040016 Jul  6 21:06 train-images-idx3-ubyte\r\n-rw-rw---- 1 wsuser watsonstudio    60008 Jul  6 21:06 train-labels-idx1-ubyte\r\n"
                }
            ],
            "source": "!mkdir kmnistdata\n!cp t10k-images-idx3-ubyte kmnistdata/t10k-images-idx3-ubyte\n!cp t10k-labels-idx1-ubyte kmnistdata/t10k-labels-idx1-ubyte\n!cp train-images-idx3-ubyte kmnistdata/train-images-idx3-ubyte\n!cp train-labels-idx1-ubyte kmnistdata/train-labels-idx1-ubyte\n!ls -al kmnistdata\n\ndata = MNIST('kmnistdata')\ntrain_images, train_labels = data.load_training()\ntest_images, test_labels = data.load_testing()\n\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\n\ntrain_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size = 0.2, random_state=39)\n\ntrain_images = train_images / 255\nval_images = val_images / 255\ntest_images = test_images / 255"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "# model_1 def\n\nmodel_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_1 compile\nmodel_1.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.6649 - accuracy: 0.7991 - val_loss: 0.2637 - val_accuracy: 0.9208\nEpoch 2/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.2289 - accuracy: 0.9338 - val_loss: 0.2120 - val_accuracy: 0.9366\nEpoch 3/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.1456 - accuracy: 0.9581 - val_loss: 0.1906 - val_accuracy: 0.9412\nEpoch 4/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9695 - val_loss: 0.1754 - val_accuracy: 0.9475\nEpoch 5/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0808 - accuracy: 0.9780 - val_loss: 0.1725 - val_accuracy: 0.9503\nEpoch 6/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0598 - accuracy: 0.9837 - val_loss: 0.1786 - val_accuracy: 0.9484\nEpoch 7/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0428 - accuracy: 0.9892 - val_loss: 0.1921 - val_accuracy: 0.9463\nEpoch 8/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.1863 - val_accuracy: 0.9513\nEpoch 9/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.2064 - val_accuracy: 0.9477\nEpoch 10/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.2091 - val_accuracy: 0.9504\nEpoch 11/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.2378 - val_accuracy: 0.9453\nEpoch 12/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.2271 - val_accuracy: 0.9500\nEpoch 13/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.2339 - val_accuracy: 0.9508\nEpoch 14/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.2574 - val_accuracy: 0.9494\nEpoch 15/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.2444 - val_accuracy: 0.9505\nEpoch 16/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.2600 - val_accuracy: 0.9488\nEpoch 17/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.2693 - val_accuracy: 0.9526\nEpoch 18/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.2563 - val_accuracy: 0.9532\nEpoch 19/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.2756 - val_accuracy: 0.9523\nEpoch 20/20\n1500/1500 [==============================] - 4s 2ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.2730 - val_accuracy: 0.9514\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8bec0e8c10>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1 fit\n\n# began by using 5 epochs here but observed that \n# the validation accuracy is increasing even as we\n# stopped training, so consider using more epochs here next\n\nmodel_1.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1 test loss: 0.7422628998756409\nmodel_1 test accuracy 0.8898000121116638\n"
                }
            ],
            "source": "score = model_1.evaluate(test_images, test_labels, verbose=0)\nprint('model_1 test loss:', score[0])\nprint('model_1 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_1 def\n\nmodel_1_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_1 compile\nmodel_1_1.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.7687 - accuracy: 0.7554 - val_loss: 0.2541 - val_accuracy: 0.9207\nEpoch 2/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2931 - accuracy: 0.9109 - val_loss: 0.2060 - val_accuracy: 0.9377\nEpoch 3/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2234 - accuracy: 0.9312 - val_loss: 0.1899 - val_accuracy: 0.9438\nEpoch 4/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1942 - accuracy: 0.9399 - val_loss: 0.1709 - val_accuracy: 0.9500\nEpoch 5/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1658 - accuracy: 0.9476 - val_loss: 0.1640 - val_accuracy: 0.9516\nEpoch 6/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1471 - accuracy: 0.9530 - val_loss: 0.1629 - val_accuracy: 0.9506\nEpoch 7/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1370 - accuracy: 0.9550 - val_loss: 0.1594 - val_accuracy: 0.9523\nEpoch 8/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1305 - accuracy: 0.9573 - val_loss: 0.1560 - val_accuracy: 0.9546\nEpoch 9/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1147 - accuracy: 0.9626 - val_loss: 0.1555 - val_accuracy: 0.9557\nEpoch 10/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9625 - val_loss: 0.1587 - val_accuracy: 0.9564\nEpoch 11/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1077 - accuracy: 0.9652 - val_loss: 0.1589 - val_accuracy: 0.9567\nEpoch 12/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0994 - accuracy: 0.9674 - val_loss: 0.1562 - val_accuracy: 0.9567\nEpoch 13/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0948 - accuracy: 0.9696 - val_loss: 0.1579 - val_accuracy: 0.9603\nEpoch 14/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0900 - accuracy: 0.9706 - val_loss: 0.1641 - val_accuracy: 0.9566\nEpoch 15/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0876 - accuracy: 0.9702 - val_loss: 0.1564 - val_accuracy: 0.9577\nEpoch 16/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0833 - accuracy: 0.9730 - val_loss: 0.1640 - val_accuracy: 0.9553\nEpoch 17/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0836 - accuracy: 0.9725 - val_loss: 0.1719 - val_accuracy: 0.9576\nEpoch 18/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0854 - accuracy: 0.9731 - val_loss: 0.1657 - val_accuracy: 0.9561\nEpoch 19/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0787 - accuracy: 0.9752 - val_loss: 0.1733 - val_accuracy: 0.9575\nEpoch 20/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0762 - accuracy: 0.9746 - val_loss: 0.1756 - val_accuracy: 0.9564\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8bec01ae10>"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_1 fit\nmodel_1_1.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (32, 128)                 100480    \n_________________________________________________________________\ndropout (Dropout)            (32, 128)                 0         \n_________________________________________________________________\ndense_3 (Dense)              (32, 128)                 16512     \n_________________________________________________________________\ndropout_1 (Dropout)          (32, 128)                 0         \n_________________________________________________________________\ndense_4 (Dense)              (32, 10)                  1290      \n=================================================================\nTotal params: 118,282\nTrainable params: 118,282\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "model_1_1.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_1 test loss: 0.4759407341480255\nmodel_1_1 test accuracy 0.892300009727478\n"
                }
            ],
            "source": "score = model_1_1.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_1 test loss:', score[0])\nprint('model_1_1 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2 def\n\nmodel_1_2 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2 compile\nmodel_1_2.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.6492 - accuracy: 0.7954 - val_loss: 0.2544 - val_accuracy: 0.9208\nEpoch 2/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1985 - accuracy: 0.9398 - val_loss: 0.1897 - val_accuracy: 0.9441\nEpoch 3/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1380 - accuracy: 0.9580 - val_loss: 0.1827 - val_accuracy: 0.9473\nEpoch 4/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1004 - accuracy: 0.9685 - val_loss: 0.1801 - val_accuracy: 0.9492\nEpoch 5/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9746 - val_loss: 0.2108 - val_accuracy: 0.9409\nEpoch 6/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0682 - accuracy: 0.9793 - val_loss: 0.1901 - val_accuracy: 0.9522\nEpoch 7/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0528 - accuracy: 0.9840 - val_loss: 0.1893 - val_accuracy: 0.9535\nEpoch 8/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0491 - accuracy: 0.9842 - val_loss: 0.2154 - val_accuracy: 0.9435\nEpoch 9/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.2152 - val_accuracy: 0.9531\nEpoch 10/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.2100 - val_accuracy: 0.9503\nEpoch 11/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.1890 - val_accuracy: 0.9572\nEpoch 12/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.2301 - val_accuracy: 0.9498\nEpoch 13/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.1963 - val_accuracy: 0.9559\nEpoch 14/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.2217 - val_accuracy: 0.9537\nEpoch 15/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.2165 - val_accuracy: 0.9560\nEpoch 16/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.2193 - val_accuracy: 0.9582\nEpoch 17/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.2345 - val_accuracy: 0.9562\nEpoch 18/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.2160 - val_accuracy: 0.9562\nEpoch 19/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.2409 - val_accuracy: 0.9540\nEpoch 20/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.2686 - val_accuracy: 0.9561\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b4c61ee50>"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_2 fit\nmodel_1_2.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (32, 128)                 100480    \n_________________________________________________________________\ndense_6 (Dense)              (32, 128)                 16512     \n_________________________________________________________________\ndense_7 (Dense)              (32, 128)                 16512     \n_________________________________________________________________\ndense_8 (Dense)              (32, 128)                 16512     \n_________________________________________________________________\ndense_9 (Dense)              (32, 10)                  1290      \n=================================================================\nTotal params: 151,306\nTrainable params: 151,306\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "model_1_2.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_2 test loss: 0.755105197429657\nmodel_1_2 test accuracy 0.8855000138282776\n"
                }
            ],
            "source": "score = model_1_2.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_2 test loss:', score[0])\nprint('model_1_2 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_3 def\n\nmodel_1_3 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_3 compile\nmodel_1_3.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 6s 3ms/step - loss: 0.7879 - accuracy: 0.7441 - val_loss: 0.2740 - val_accuracy: 0.9162\nEpoch 2/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2543 - accuracy: 0.9245 - val_loss: 0.2046 - val_accuracy: 0.9371\nEpoch 3/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.1856 - accuracy: 0.9452 - val_loss: 0.1845 - val_accuracy: 0.9461\nEpoch 4/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.1473 - accuracy: 0.9556 - val_loss: 0.1837 - val_accuracy: 0.9461\nEpoch 5/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.1192 - accuracy: 0.9650 - val_loss: 0.2088 - val_accuracy: 0.9425\nEpoch 6/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.1028 - accuracy: 0.9686 - val_loss: 0.1925 - val_accuracy: 0.9503\nEpoch 7/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0899 - accuracy: 0.9716 - val_loss: 0.1894 - val_accuracy: 0.9501\nEpoch 8/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9753 - val_loss: 0.1921 - val_accuracy: 0.9518\nEpoch 9/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9787 - val_loss: 0.1761 - val_accuracy: 0.9563\nEpoch 10/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.1854 - val_accuracy: 0.9558\nEpoch 11/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.1928 - val_accuracy: 0.9537\nEpoch 12/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.1858 - val_accuracy: 0.9558\nEpoch 13/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.2080 - val_accuracy: 0.9542\nEpoch 14/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0433 - accuracy: 0.9871 - val_loss: 0.2111 - val_accuracy: 0.9553\nEpoch 15/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.2001 - val_accuracy: 0.9544\nEpoch 16/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.2085 - val_accuracy: 0.9553\nEpoch 17/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 0.2073 - val_accuracy: 0.9555\nEpoch 18/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0375 - accuracy: 0.9892 - val_loss: 0.2270 - val_accuracy: 0.9530\nEpoch 19/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.2253 - val_accuracy: 0.9553\nEpoch 20/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.2291 - val_accuracy: 0.9526\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b4c485550>"
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_3 fit\nmodel_1_3.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_3 test loss: 0.5735206007957458\nmodel_1_3 test accuracy 0.8925999999046326\n"
                }
            ],
            "source": "score = model_1_3.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_3 test loss:', score[0])\nprint('model_1_3 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_4 def\n\nmodel_1_4 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_4 compile\n\nmodel_1_4.compile(optimizer=tf.keras.optimizers.Adadelta(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 2.2875 - accuracy: 0.1197 - val_loss: 2.2531 - val_accuracy: 0.2028\nEpoch 2/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 2.2394 - accuracy: 0.2291 - val_loss: 2.2018 - val_accuracy: 0.2755\nEpoch 3/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 2.1866 - accuracy: 0.2825 - val_loss: 2.1404 - val_accuracy: 0.3061\nEpoch 4/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 2.1215 - accuracy: 0.3168 - val_loss: 2.0678 - val_accuracy: 0.3363\nEpoch 5/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 2.0486 - accuracy: 0.3438 - val_loss: 1.9851 - val_accuracy: 0.3720\nEpoch 6/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.9689 - accuracy: 0.3777 - val_loss: 1.8948 - val_accuracy: 0.4141\nEpoch 7/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.8720 - accuracy: 0.4223 - val_loss: 1.7987 - val_accuracy: 0.4588\nEpoch 8/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.7782 - accuracy: 0.4630 - val_loss: 1.7000 - val_accuracy: 0.5012\nEpoch 9/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.6823 - accuracy: 0.5089 - val_loss: 1.6020 - val_accuracy: 0.5485\nEpoch 10/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.5855 - accuracy: 0.5533 - val_loss: 1.5082 - val_accuracy: 0.5868\nEpoch 11/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.4898 - accuracy: 0.5959 - val_loss: 1.4217 - val_accuracy: 0.6248\nEpoch 12/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.4048 - accuracy: 0.6307 - val_loss: 1.3444 - val_accuracy: 0.6525\nEpoch 13/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.3348 - accuracy: 0.6530 - val_loss: 1.2760 - val_accuracy: 0.6718\nEpoch 14/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.2635 - accuracy: 0.6716 - val_loss: 1.2155 - val_accuracy: 0.6873\nEpoch 15/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.2143 - accuracy: 0.6811 - val_loss: 1.1620 - val_accuracy: 0.6962\nEpoch 16/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.1566 - accuracy: 0.6945 - val_loss: 1.1148 - val_accuracy: 0.7038\nEpoch 17/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.1092 - accuracy: 0.7017 - val_loss: 1.0730 - val_accuracy: 0.7105\nEpoch 18/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.0700 - accuracy: 0.7093 - val_loss: 1.0355 - val_accuracy: 0.7184\nEpoch 19/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.0329 - accuracy: 0.7139 - val_loss: 1.0019 - val_accuracy: 0.7244\nEpoch 20/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.0010 - accuracy: 0.7211 - val_loss: 0.9715 - val_accuracy: 0.7300\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b4c32f110>"
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_4 fit\n\nmodel_1_4.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_4 test loss: 1.3908430337905884\nmodel_1_4 test accuracy 0.569100022315979\n"
                }
            ],
            "source": "score = model_1_4.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_4 test loss:', score[0])\nprint('model_1_4 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_4_1 def (using the dropouts with adadelta)\n\nmodel_1_4_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_4_1 compile\n\nmodel_1_4_1.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 1.0),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.7651 - accuracy: 0.7566 - val_loss: 0.2681 - val_accuracy: 0.9169\nEpoch 2/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3004 - accuracy: 0.9087 - val_loss: 0.2053 - val_accuracy: 0.9390\nEpoch 3/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2459 - accuracy: 0.9257 - val_loss: 0.1834 - val_accuracy: 0.9461\nEpoch 4/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9396 - val_loss: 0.1820 - val_accuracy: 0.9464\nEpoch 5/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1822 - accuracy: 0.9451 - val_loss: 0.1738 - val_accuracy: 0.9496\nEpoch 6/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1671 - accuracy: 0.9487 - val_loss: 0.1756 - val_accuracy: 0.9494\nEpoch 7/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1532 - accuracy: 0.9530 - val_loss: 0.1665 - val_accuracy: 0.9517\nEpoch 8/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1395 - accuracy: 0.9578 - val_loss: 0.1655 - val_accuracy: 0.9517\nEpoch 9/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1326 - accuracy: 0.9595 - val_loss: 0.1688 - val_accuracy: 0.9527\nEpoch 10/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1244 - accuracy: 0.9616 - val_loss: 0.1643 - val_accuracy: 0.9542\nEpoch 11/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1136 - accuracy: 0.9651 - val_loss: 0.1665 - val_accuracy: 0.9553\nEpoch 12/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1093 - accuracy: 0.9673 - val_loss: 0.1695 - val_accuracy: 0.9551\nEpoch 13/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1061 - accuracy: 0.9664 - val_loss: 0.1715 - val_accuracy: 0.9564\nEpoch 14/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0990 - accuracy: 0.9698 - val_loss: 0.1793 - val_accuracy: 0.9538\nEpoch 15/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1026 - accuracy: 0.9695 - val_loss: 0.1760 - val_accuracy: 0.9546\nEpoch 16/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0984 - accuracy: 0.9705 - val_loss: 0.1815 - val_accuracy: 0.9545\nEpoch 17/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0881 - accuracy: 0.9723 - val_loss: 0.1808 - val_accuracy: 0.9554\nEpoch 18/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.1832 - val_accuracy: 0.9548\nEpoch 19/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0854 - accuracy: 0.9746 - val_loss: 0.1895 - val_accuracy: 0.9542\nEpoch 20/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0889 - accuracy: 0.9737 - val_loss: 0.1910 - val_accuracy: 0.9547\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b4c106e90>"
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_4_1 fit\n\nmodel_1_4_1.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_4_1 test loss: 0.5012156367301941\nmodel_1_4_1 test accuracy 0.8932999968528748\n"
                }
            ],
            "source": "score = model_1_4_1.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_4_1 test loss:', score[0])\nprint('model_1_4_1 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5 def\n\nmodel_1_5 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5 compile\n\nmodel_1_5.compile(optimizer='sgd',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 5s 3ms/step - loss: 1.6107 - accuracy: 0.4708 - val_loss: 0.5670 - val_accuracy: 0.8272\nEpoch 2/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.5150 - accuracy: 0.8446 - val_loss: 0.3987 - val_accuracy: 0.8789\nEpoch 3/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3817 - accuracy: 0.8859 - val_loss: 0.3519 - val_accuracy: 0.8922\nEpoch 4/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3098 - accuracy: 0.9067 - val_loss: 0.2914 - val_accuracy: 0.9107\nEpoch 5/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2620 - accuracy: 0.9237 - val_loss: 0.2657 - val_accuracy: 0.9185\nEpoch 6/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2283 - accuracy: 0.9322 - val_loss: 0.2466 - val_accuracy: 0.9245\nEpoch 7/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1901 - accuracy: 0.9446 - val_loss: 0.2382 - val_accuracy: 0.9275\nEpoch 8/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1706 - accuracy: 0.9514 - val_loss: 0.2213 - val_accuracy: 0.9302\nEpoch 9/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1519 - accuracy: 0.9572 - val_loss: 0.2184 - val_accuracy: 0.9318\nEpoch 10/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1377 - accuracy: 0.9610 - val_loss: 0.2061 - val_accuracy: 0.9353\nEpoch 11/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1185 - accuracy: 0.9659 - val_loss: 0.2008 - val_accuracy: 0.9383\nEpoch 12/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1036 - accuracy: 0.9706 - val_loss: 0.2023 - val_accuracy: 0.9395\nEpoch 13/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0887 - accuracy: 0.9758 - val_loss: 0.2140 - val_accuracy: 0.9344\nEpoch 14/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0825 - accuracy: 0.9783 - val_loss: 0.1995 - val_accuracy: 0.9416\nEpoch 15/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0717 - accuracy: 0.9808 - val_loss: 0.2024 - val_accuracy: 0.9433\nEpoch 16/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.2023 - val_accuracy: 0.9423\nEpoch 17/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0561 - accuracy: 0.9855 - val_loss: 0.2019 - val_accuracy: 0.9432\nEpoch 18/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0490 - accuracy: 0.9880 - val_loss: 0.2270 - val_accuracy: 0.9368\nEpoch 19/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.2091 - val_accuracy: 0.9430\nEpoch 20/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.0331 - accuracy: 0.9927 - val_loss: 0.2169 - val_accuracy: 0.9427\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b2876a8d0>"
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_5 fit\n\nmodel_1_5.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_5 test loss: 0.5508348941802979\nmodel_1_5 test accuracy 0.8748999834060669\n"
                }
            ],
            "source": "score = model_1_5.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_5 test loss:', score[0])\nprint('model_1_5 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5_1 def\n\nmodel_1_5_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5_1 compile\n\nmodel_1_5_1.compile(optimizer='sgd',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 1.5708 - accuracy: 0.4783 - val_loss: 0.6132 - val_accuracy: 0.8180\nEpoch 2/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.7001 - accuracy: 0.7861 - val_loss: 0.4537 - val_accuracy: 0.8627\nEpoch 3/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.5592 - accuracy: 0.8266 - val_loss: 0.3842 - val_accuracy: 0.8829\nEpoch 4/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.4809 - accuracy: 0.8525 - val_loss: 0.3433 - val_accuracy: 0.8952\nEpoch 5/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.4172 - accuracy: 0.8721 - val_loss: 0.3153 - val_accuracy: 0.9029\nEpoch 6/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3860 - accuracy: 0.8821 - val_loss: 0.2926 - val_accuracy: 0.9091\nEpoch 7/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3527 - accuracy: 0.8936 - val_loss: 0.2757 - val_accuracy: 0.9158\nEpoch 8/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3319 - accuracy: 0.8997 - val_loss: 0.2604 - val_accuracy: 0.9197\nEpoch 9/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3137 - accuracy: 0.9049 - val_loss: 0.2462 - val_accuracy: 0.9251\nEpoch 10/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.3033 - accuracy: 0.9078 - val_loss: 0.2358 - val_accuracy: 0.9291\nEpoch 11/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2798 - accuracy: 0.9153 - val_loss: 0.2280 - val_accuracy: 0.9304\nEpoch 12/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2696 - accuracy: 0.9188 - val_loss: 0.2217 - val_accuracy: 0.9326\nEpoch 13/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2602 - accuracy: 0.9202 - val_loss: 0.2127 - val_accuracy: 0.9349\nEpoch 14/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2503 - accuracy: 0.9234 - val_loss: 0.2073 - val_accuracy: 0.9367\nEpoch 15/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2397 - accuracy: 0.9271 - val_loss: 0.2032 - val_accuracy: 0.9379\nEpoch 16/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2297 - accuracy: 0.9307 - val_loss: 0.1981 - val_accuracy: 0.9394\nEpoch 17/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2239 - accuracy: 0.9303 - val_loss: 0.1954 - val_accuracy: 0.9402\nEpoch 18/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2167 - accuracy: 0.9338 - val_loss: 0.1913 - val_accuracy: 0.9423\nEpoch 19/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.2091 - accuracy: 0.9370 - val_loss: 0.1870 - val_accuracy: 0.9436\nEpoch 20/20\n1500/1500 [==============================] - 4s 3ms/step - loss: 0.1988 - accuracy: 0.9381 - val_loss: 0.1849 - val_accuracy: 0.9438\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b28665f90>"
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_5_1 fit\n\nmodel_1_5_1.fit(train_images, train_labels, epochs=20, verbose=1, validation_data=(val_images, val_labels))"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_5_1 test loss: 0.4522767663002014\nmodel_1_5_1 test accuracy 0.8659999966621399\n"
                }
            ],
            "source": "score = model_1_5_1.evaluate(test_images, test_labels, verbose=0)\nprint('model_1_5_1 test loss:', score[0])\nprint('model_1_5_1 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# model_2 def\n\n# optimizer is adam and loss is sparse_categorical_crossentropy\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\nx_train = train_images\nx_val = val_images\nx_test = test_images\n\ny_train = train_labels\ny_val = val_labels\ny_test = test_labels\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_val = x_val.reshape(x_val.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nmodel_2 = tf.keras.Sequential()\nmodel_2.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(Dropout(0.25))\nmodel_2.add(tf.keras.layers.Flatten())\nmodel_2.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2.add(Dropout(0.5))\nmodel_2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\n# model_2 compile\n\nmodel_2.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n375/375 [==============================] - 14s 20ms/step - loss: 0.7943 - accuracy: 0.7457 - val_loss: 0.1358 - val_accuracy: 0.9602\nEpoch 2/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.2116 - accuracy: 0.9365 - val_loss: 0.0923 - val_accuracy: 0.9719\nEpoch 3/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1430 - accuracy: 0.9556 - val_loss: 0.0785 - val_accuracy: 0.9760\nEpoch 4/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1194 - accuracy: 0.9633 - val_loss: 0.0753 - val_accuracy: 0.9772\nEpoch 5/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0961 - accuracy: 0.9698 - val_loss: 0.0733 - val_accuracy: 0.9779\nEpoch 6/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0883 - accuracy: 0.9711 - val_loss: 0.0693 - val_accuracy: 0.9804\nEpoch 7/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0704 - accuracy: 0.9767 - val_loss: 0.0638 - val_accuracy: 0.9821\nEpoch 8/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0627 - accuracy: 0.9796 - val_loss: 0.0685 - val_accuracy: 0.9821\nEpoch 9/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0579 - accuracy: 0.9820 - val_loss: 0.0646 - val_accuracy: 0.9833\nEpoch 10/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.0656 - val_accuracy: 0.9837\nEpoch 11/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0489 - accuracy: 0.9832 - val_loss: 0.0669 - val_accuracy: 0.9834\nEpoch 12/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0428 - accuracy: 0.9856 - val_loss: 0.0673 - val_accuracy: 0.9827\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fb948c9ca50>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model\n\nmodel_2.fit(x_train, y_train,\n         batch_size=batch_size,\n         epochs=epochs,\n         verbose=1,\n         validation_data=(x_val, y_val))"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_2 test loss: 0.2627474069595337\nmodel_2 test accuracy 0.9430999755859375\n"
                }
            ],
            "source": "score = model_2.evaluate(x_test, y_test, verbose=0)\nprint('model_2 test loss:', score[0])\nprint('model_2 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": "# model_2_1 def : change of optimizer to Adadelta and compile\n\nmodel_2_1 = tf.keras.Sequential()\nmodel_2_1.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_1.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_1.add(Dropout(0.25))\nmodel_2_1.add(tf.keras.layers.Flatten())\nmodel_2_1.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_1.add(Dropout(0.5))\nmodel_2_1.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_1.compile(loss='sparse_categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0),\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n375/375 [==============================] - 5s 14ms/step - loss: 0.8610 - accuracy: 0.7215 - val_loss: 0.1486 - val_accuracy: 0.9558\nEpoch 2/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.2128 - accuracy: 0.9373 - val_loss: 0.1083 - val_accuracy: 0.9677\nEpoch 3/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1476 - accuracy: 0.9537 - val_loss: 0.0863 - val_accuracy: 0.9738\nEpoch 4/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1169 - accuracy: 0.9642 - val_loss: 0.0788 - val_accuracy: 0.9771\nEpoch 5/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0985 - accuracy: 0.9699 - val_loss: 0.0741 - val_accuracy: 0.9787\nEpoch 6/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0863 - accuracy: 0.9744 - val_loss: 0.0693 - val_accuracy: 0.9802\nEpoch 7/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 0.0646 - val_accuracy: 0.9818\nEpoch 8/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0668 - accuracy: 0.9792 - val_loss: 0.0674 - val_accuracy: 0.9814\nEpoch 9/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0646 - accuracy: 0.9804 - val_loss: 0.0687 - val_accuracy: 0.9825\nEpoch 10/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 0.0726 - val_accuracy: 0.9821\nEpoch 11/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.0662 - val_accuracy: 0.9819\nEpoch 12/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.0654 - val_accuracy: 0.9814\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b2804a850>"
                    },
                    "execution_count": 46,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_1.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_9 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-47-ff657562e8fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_1 test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_1 test accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_9 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n"
                    ]
                }
            ],
            "source": "score = model_2_1.evaluate(test_images, test_labels, verbose=0)\nprint('model_2_1 test loss:', score[0])\nprint('model_2_1 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Adamax\n\n# model_2_2: change of optimizer to Adamax and compile\n\nmodel_2_2 = tf.keras.Sequential()\nmodel_2_2.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_2.add(Dropout(0.25))\nmodel_2_2.add(tf.keras.layers.Flatten())\nmodel_2_2.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_2.add(Dropout(0.5))\nmodel_2_2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_2.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Adamax',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n375/375 [==============================] - 5s 14ms/step - loss: 0.9374 - accuracy: 0.7041 - val_loss: 0.2443 - val_accuracy: 0.9268\nEpoch 2/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.3240 - accuracy: 0.9021 - val_loss: 0.1580 - val_accuracy: 0.9517\nEpoch 3/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.2390 - accuracy: 0.9293 - val_loss: 0.1272 - val_accuracy: 0.9617\nEpoch 4/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1943 - accuracy: 0.9431 - val_loss: 0.1069 - val_accuracy: 0.9688\nEpoch 5/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1685 - accuracy: 0.9486 - val_loss: 0.1000 - val_accuracy: 0.9712\nEpoch 6/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1485 - accuracy: 0.9544 - val_loss: 0.0887 - val_accuracy: 0.9737\nEpoch 7/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1292 - accuracy: 0.9612 - val_loss: 0.0855 - val_accuracy: 0.9748\nEpoch 8/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1208 - accuracy: 0.9625 - val_loss: 0.0800 - val_accuracy: 0.9778\nEpoch 9/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.1062 - accuracy: 0.9670 - val_loss: 0.0768 - val_accuracy: 0.9778\nEpoch 10/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0972 - accuracy: 0.9709 - val_loss: 0.0750 - val_accuracy: 0.9779\nEpoch 11/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 0.0705 - val_accuracy: 0.9800\nEpoch 12/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.0846 - accuracy: 0.9731 - val_loss: 0.0695 - val_accuracy: 0.9807\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b04647190>"
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_2.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-50-f621ea8f014f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_2 test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_2 test accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n"
                    ]
                }
            ],
            "source": "score = model_2_2.evaluate(test_images, test_labels, verbose=0)\nprint('model_2_2 test loss:', score[0])\nprint('model_2_2 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Adagrad\n\n# model_2_3: change of optimizer to Adagrad and compile\n\nmodel_2_3 = tf.keras.Sequential()\nmodel_2_3.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_3.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_3.add(Dropout(0.25))\nmodel_2_3.add(tf.keras.layers.Flatten())\nmodel_2_3.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_3.add(Dropout(0.5))\nmodel_2_3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_3.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Adagrad',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n375/375 [==============================] - 5s 14ms/step - loss: 2.1988 - accuracy: 0.2127 - val_loss: 1.4210 - val_accuracy: 0.6712\nEpoch 2/12\n375/375 [==============================] - 5s 13ms/step - loss: 1.3975 - accuracy: 0.5669 - val_loss: 0.8842 - val_accuracy: 0.7550\nEpoch 3/12\n375/375 [==============================] - 5s 13ms/step - loss: 1.0296 - accuracy: 0.6825 - val_loss: 0.7028 - val_accuracy: 0.8032\nEpoch 4/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.8749 - accuracy: 0.7328 - val_loss: 0.6080 - val_accuracy: 0.8230\nEpoch 5/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.7945 - accuracy: 0.7546 - val_loss: 0.5479 - val_accuracy: 0.8405\nEpoch 6/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.7415 - accuracy: 0.7715 - val_loss: 0.5058 - val_accuracy: 0.8512\nEpoch 7/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.7023 - accuracy: 0.7833 - val_loss: 0.4734 - val_accuracy: 0.8603\nEpoch 8/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.6659 - accuracy: 0.7961 - val_loss: 0.4505 - val_accuracy: 0.8682\nEpoch 9/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.6498 - accuracy: 0.8001 - val_loss: 0.4296 - val_accuracy: 0.8731\nEpoch 10/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.6183 - accuracy: 0.8061 - val_loss: 0.4131 - val_accuracy: 0.8775\nEpoch 11/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.6015 - accuracy: 0.8125 - val_loss: 0.3979 - val_accuracy: 0.8817\nEpoch 12/12\n375/375 [==============================] - 5s 13ms/step - loss: 0.5963 - accuracy: 0.8144 - val_loss: 0.3855 - val_accuracy: 0.8840\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b0455b710>"
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_3.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_11 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-53-5464e667b47c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_3 test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_3 test accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_11 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n"
                    ]
                }
            ],
            "source": "score = model_2_3.evaluate(test_images, test_labels, verbose=0)\nprint('model_2_3 test loss:', score[0])\nprint('model_2_3 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": "# optimizer = Nadam\n\n# model_2_4: change of optimizer to Nadam and compile\n\nmodel_2_4 = tf.keras.Sequential()\nmodel_2_4.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_4.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_4.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_4.add(Dropout(0.25))\nmodel_2_4.add(tf.keras.layers.Flatten())\nmodel_2_4.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_4.add(Dropout(0.5))\nmodel_2_4.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\nmodel_2_4.compile(loss='sparse_categorical_crossentropy',\n              optimizer='Nadam',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n375/375 [==============================] - 8s 17ms/step - loss: 0.7535 - accuracy: 0.7615 - val_loss: 0.1198 - val_accuracy: 0.9652\nEpoch 2/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.1915 - accuracy: 0.9425 - val_loss: 0.0852 - val_accuracy: 0.9743\nEpoch 3/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.1297 - accuracy: 0.9607 - val_loss: 0.0715 - val_accuracy: 0.9790\nEpoch 4/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.1044 - accuracy: 0.9675 - val_loss: 0.0686 - val_accuracy: 0.9797\nEpoch 5/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0840 - accuracy: 0.9733 - val_loss: 0.0681 - val_accuracy: 0.9803\nEpoch 6/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.0625 - val_accuracy: 0.9818\nEpoch 7/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0628 - accuracy: 0.9794 - val_loss: 0.0618 - val_accuracy: 0.9827\nEpoch 8/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 0.0630 - val_accuracy: 0.9823\nEpoch 9/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.0629 - val_accuracy: 0.9833\nEpoch 10/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 0.0582 - val_accuracy: 0.9847\nEpoch 11/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.0620 - val_accuracy: 0.9843\nEpoch 12/12\n375/375 [==============================] - 6s 16ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0596 - val_accuracy: 0.9843\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b044e4c90>"
                    },
                    "execution_count": 55,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_2_4.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "score = model_2_4.evaluate(test_images, test_labels, verbose=0)\nprint('model_2_4 test loss:', score[0])\nprint('model_2_4 test accuracy', score[1])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### This is the first dataset in .npz format"
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-07-02 20:35:47--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 18384171 (18M)\nSaving to: \u2018kmnist-train-imgs.npz?raw=True\u2019\n\nkmnist-train-imgs.n 100%[===================>]  17.53M  7.55MB/s    in 2.3s    \n\n2021-07-02 20:35:50 (7.55 MB/s) - \u2018kmnist-train-imgs.npz?raw=True\u2019 saved [18384171/18384171]\n\n-rw-rw---- 1 wsuser watsonstudio 18M Feb  4  2019 kmnist-train-imgs.npz\n--2021-07-02 20:35:52--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 29700 (29K)\nSaving to: \u2018kmnist-train-labels.npz?raw=True\u2019\n\nkmnist-train-labels 100%[===================>]  29.00K  --.-KB/s    in 0.1s    \n\n2021-07-02 20:35:53 (197 KB/s) - \u2018kmnist-train-labels.npz?raw=True\u2019 saved [29700/29700]\n\n-rw-rw---- 1 wsuser watsonstudio 30K Feb  4  2019 kmnist-train-labels.npz\n--2021-07-02 20:35:55--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3079479 (2.9M)\nSaving to: \u2018kmnist-test-imgs.npz?raw=True\u2019\n\nkmnist-test-imgs.np 100%[===================>]   2.94M  2.74MB/s    in 1.1s    \n\n2021-07-02 20:35:56 (2.74 MB/s) - \u2018kmnist-test-imgs.npz?raw=True\u2019 saved [3079479/3079479]\n\n-rw-rw---- 1 wsuser watsonstudio 3.0M Feb  4  2019 kmnist-test-imgs.npz\n--2021-07-02 20:35:58--  http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5304 (5.2K)\nSaving to: \u2018kmnist-test-labels.npz?raw=True\u2019\n\nkmnist-test-labels. 100%[===================>]   5.18K  --.-KB/s    in 0s      \n\n2021-07-02 20:36:00 (288 MB/s) - \u2018kmnist-test-labels.npz?raw=True\u2019 saved [5304/5304]\n\n-rw-rw---- 1 wsuser watsonstudio 5.2K Feb  4  2019 kmnist-test-labels.npz\n"
                }
            ],
            "source": "!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz?raw=True\n!mv kmnist-train-imgs.npz?raw=True kmnist-train-imgs.npz\n!ls -lahr kmnist-train-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz?raw=True\n!mv kmnist-train-labels.npz?raw=True kmnist-train-labels.npz\n!ls -lahr kmnist-train-labels.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz?raw=True\n!mv kmnist-test-imgs.npz?raw=True kmnist-test-imgs.npz\n!ls -lahr kmnist-test-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz?raw=True\n!mv kmnist-test-labels.npz?raw=True kmnist-test-labels.npz\n!ls -lahr kmnist-test-labels.npz"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model:  K Nearest Neighbors"
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": "def load(f):\n    return np.load(f)['arr_0']"
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": "x_train = load('kmnist-train-imgs.npz')\ny_train = load('kmnist-train-labels.npz')\nx_test = load('kmnist-test-imgs.npz')\ny_test = load('kmnist-test-labels.npz')"
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": "x_train = x_train.reshape(-1, 784)\nx_test = x_test.reshape(-1, 784)"
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fit KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n"
                },
                {
                    "data": {
                        "text/plain": "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model_0 = KNeighborsClassifier(n_neighbors=4, weights='distance', n_jobs=-1)\nprint('Fit', model_0)\nmodel_0.fit(x_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Evaluate KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\nThe accuracy is: 0.921\n"
                }
            ],
            "source": "print('Evaluate', model_0)\nscore = model_0.score(x_test, y_test)\nprint('The accuracy is:', score)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Dataset 2\n\n#### 232,365 images, 49 classes, each image is 28 x 28 or represented by a 794 element array"
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-07-02 20:38:36--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 66117696 (63M)\nSaving to: \u2018k49-train-imgs.npz?raw=True\u2019\n\nk49-train-imgs.npz? 100%[===================>]  63.05M  7.69MB/s    in 8.7s    \n\n2021-07-02 20:38:45 (7.24 MB/s) - \u2018k49-train-imgs.npz?raw=True\u2019 saved [66117696/66117696]\n\n-rw-rw---- 1 wsuser watsonstudio 64M Feb  4  2019 k49-train-imgs.npz\n--2021-07-02 20:38:47--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 164485 (161K)\nSaving to: \u2018k49-train-labels.npz?raw=True\u2019\n\nk49-train-labels.np 100%[===================>] 160.63K   369KB/s    in 0.4s    \n\n2021-07-02 20:38:48 (369 KB/s) - \u2018k49-train-labels.npz?raw=True\u2019 saved [164485/164485]\n\n-rw-rw---- 1 wsuser watsonstudio 161K Feb  4  2019 k49-train-labels.npz\n--2021-07-02 20:38:50--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10971201 (10M)\nSaving to: \u2018k49-test-imgs.npz?raw=True\u2019\n\nk49-test-imgs.npz?r 100%[===================>]  10.46M  5.16MB/s    in 2.0s    \n\n2021-07-02 20:38:52 (5.16 MB/s) - \u2018k49-test-imgs.npz?raw=True\u2019 saved [10971201/10971201]\n\n-rw-rw---- 1 wsuser watsonstudio 11M Feb  4  2019 k49-test-imgs.npz\n--2021-07-02 20:38:54--  http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 27450 (27K)\nSaving to: \u2018k49-test-labels.npz?raw=True\u2019\n\nk49-test-labels.npz 100%[===================>]  26.81K  --.-KB/s    in 0.1s    \n\n2021-07-02 20:38:55 (189 KB/s) - \u2018k49-test-labels.npz?raw=True\u2019 saved [27450/27450]\n\n-rw-rw---- 1 wsuser watsonstudio 27K Feb  4  2019 k49-test-labels.npz\n"
                }
            ],
            "source": "# download the train and test labels and images, \n# which are available onlyh in .npz format \n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz?raw=True\n!mv k49-train-imgs.npz?raw=True k49-train-imgs.npz\n!ls -lahr k49-train-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz?raw=True\n!mv k49-train-labels.npz?raw=True k49-train-labels.npz\n!ls -lahr k49-train-labels.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz?raw=True\n!mv k49-test-imgs.npz?raw=True k49-test-imgs.npz\n!ls -lahr k49-test-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz?raw=True\n!mv k49-test-labels.npz?raw=True k49-test-labels.npz\n!ls -lahr k49-test-labels.npz"
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": "def load(f):\n    return np.load(f)['arr_0']"
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": "x_train_k49 = load('k49-train-imgs.npz')\ny_train_k49 = load('k49-train-labels.npz')\nx_test_k49 = load('k49-test-imgs.npz')\ny_test_k49 = load('k49-test-labels.npz')\n\nx_train_k49 = x_train_k49.reshape(-1, 784)\nx_test_k49 = x_test_k49.reshape(-1, 784)\n\n\n# the numpy arrays used in the keras models need to be between 0 and 1\n# we keep x_train_k49 and x_test_k49 in the format of between 0 and 255\n# for use in the K-nearest Neighbors model below\n\n# create the validattion set\n\nx_train_k49, x_val_k49, y_train_k49, y_val_k49 = train_test_split(x_train_k49, y_train_k49, test_size = 0.2, random_state=35)\n\n# we need to normalize the numpy arrays so that each number in the numpy\n# array is between 0 and 1:\n\ntrain_images_k49 = x_train_k49 / 255\nval_images_k49 = x_val_k49 / 255\ntest_images_k49 = x_test_k49 / 255\n\n# and the labels can be the same\n\ntrain_labels_k49 = y_train_k49\nval_labels_k49 = y_val_k49\ntest_labels_k49 = y_test_k49"
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_k49 def\n# we have to change the last layer due to the 49 categories\n\nmodel_1_k49 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(49, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_k49 compile\nmodel_1_k49.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 1.3346 - accuracy: 0.6691 - val_loss: 0.6867 - val_accuracy: 0.8160\nEpoch 2/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.6084 - accuracy: 0.8382 - val_loss: 0.5795 - val_accuracy: 0.8431\nEpoch 3/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.4955 - accuracy: 0.8658 - val_loss: 0.5435 - val_accuracy: 0.8555\nEpoch 4/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.4451 - accuracy: 0.8778 - val_loss: 0.5296 - val_accuracy: 0.8591\nEpoch 5/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.4067 - accuracy: 0.8878 - val_loss: 0.5191 - val_accuracy: 0.8633\nEpoch 6/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.3824 - accuracy: 0.8939 - val_loss: 0.5135 - val_accuracy: 0.8657\nEpoch 7/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.3634 - accuracy: 0.8978 - val_loss: 0.5362 - val_accuracy: 0.8639\nEpoch 8/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.3458 - accuracy: 0.9018 - val_loss: 0.5323 - val_accuracy: 0.8625\nEpoch 9/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.3322 - accuracy: 0.9064 - val_loss: 0.5374 - val_accuracy: 0.8645\nEpoch 10/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.3204 - accuracy: 0.9088 - val_loss: 0.5474 - val_accuracy: 0.8637\nEpoch 11/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.3060 - accuracy: 0.9132 - val_loss: 0.5564 - val_accuracy: 0.8618\nEpoch 12/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2980 - accuracy: 0.9140 - val_loss: 0.5597 - val_accuracy: 0.8643\nEpoch 13/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2896 - accuracy: 0.9176 - val_loss: 0.5652 - val_accuracy: 0.8652\nEpoch 14/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2821 - accuracy: 0.9179 - val_loss: 0.5779 - val_accuracy: 0.8640\nEpoch 15/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2742 - accuracy: 0.9204 - val_loss: 0.5841 - val_accuracy: 0.8652\nEpoch 16/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2671 - accuracy: 0.9220 - val_loss: 0.5929 - val_accuracy: 0.8621\nEpoch 17/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2649 - accuracy: 0.9226 - val_loss: 0.5894 - val_accuracy: 0.8643\nEpoch 18/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2537 - accuracy: 0.9258 - val_loss: 0.6061 - val_accuracy: 0.8623\nEpoch 19/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2500 - accuracy: 0.9273 - val_loss: 0.6062 - val_accuracy: 0.8658\nEpoch 20/20\n5810/5810 [==============================] - 17s 3ms/step - loss: 0.2424 - accuracy: 0.9297 - val_loss: 0.6293 - val_accuracy: 0.8618\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b28410450>"
                    },
                    "execution_count": 67,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_k49 fit\n# as in the first data set, this model could probably use more epochs\nmodel_1_k49.fit(train_images_k49, train_labels_k49, epochs=20, verbose=1, validation_data=(val_images_k49, val_labels_k49))"
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_k49 test loss: 1.1436818838119507\nmodel_1_k49 test accuracy 0.7781928777694702\n"
                }
            ],
            "source": "score = model_1_k49.evaluate(test_images_k49, test_labels_k49, verbose=0)\nprint('model_1_k49 test loss:', score[0])\nprint('model_1_k49 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2_k49 def\n\nmodel_1_2_k49 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(49, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2_k49 compile\nmodel_1_2_k49.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 1.2966 - accuracy: 0.6590 - val_loss: 0.5920 - val_accuracy: 0.8348\nEpoch 2/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.5320 - accuracy: 0.8505 - val_loss: 0.5129 - val_accuracy: 0.8574\nEpoch 3/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.4330 - accuracy: 0.8773 - val_loss: 0.4968 - val_accuracy: 0.8639\nEpoch 4/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.3788 - accuracy: 0.8917 - val_loss: 0.4635 - val_accuracy: 0.8755\nEpoch 5/20\n5810/5810 [==============================] - 20s 4ms/step - loss: 0.3378 - accuracy: 0.9017 - val_loss: 0.4821 - val_accuracy: 0.8728\nEpoch 6/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.3130 - accuracy: 0.9092 - val_loss: 0.4467 - val_accuracy: 0.8822\nEpoch 7/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2920 - accuracy: 0.9150 - val_loss: 0.4589 - val_accuracy: 0.8812\nEpoch 8/20\n5810/5810 [==============================] - 20s 4ms/step - loss: 0.2773 - accuracy: 0.9195 - val_loss: 0.4892 - val_accuracy: 0.8745\nEpoch 9/20\n5810/5810 [==============================] - 20s 4ms/step - loss: 0.2661 - accuracy: 0.9222 - val_loss: 0.4752 - val_accuracy: 0.8800\nEpoch 10/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2555 - accuracy: 0.9249 - val_loss: 0.5045 - val_accuracy: 0.8772\nEpoch 11/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2431 - accuracy: 0.9279 - val_loss: 0.5006 - val_accuracy: 0.8775\nEpoch 12/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2397 - accuracy: 0.9294 - val_loss: 0.5101 - val_accuracy: 0.8817\nEpoch 13/20\n5810/5810 [==============================] - 20s 4ms/step - loss: 0.2357 - accuracy: 0.9304 - val_loss: 0.5119 - val_accuracy: 0.8823\nEpoch 14/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2276 - accuracy: 0.9330 - val_loss: 0.5080 - val_accuracy: 0.8851\nEpoch 15/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2212 - accuracy: 0.9340 - val_loss: 0.5298 - val_accuracy: 0.8791\nEpoch 16/20\n5810/5810 [==============================] - 20s 4ms/step - loss: 0.2203 - accuracy: 0.9344 - val_loss: 0.5475 - val_accuracy: 0.8827\nEpoch 17/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2136 - accuracy: 0.9376 - val_loss: 0.5406 - val_accuracy: 0.8838\nEpoch 18/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2101 - accuracy: 0.9377 - val_loss: 0.5515 - val_accuracy: 0.8815\nEpoch 19/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 0.2046 - accuracy: 0.9393 - val_loss: 0.5602 - val_accuracy: 0.8835\nEpoch 20/20\n5810/5810 [==============================] - 20s 4ms/step - loss: 0.2035 - accuracy: 0.9402 - val_loss: 0.5778 - val_accuracy: 0.8811\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8b041f0a50>"
                    },
                    "execution_count": 71,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_2_k49 fit\nmodel_1_2_k49.fit(train_images_k49, train_labels_k49, epochs=20, verbose=1, validation_data=(val_images_k49, val_labels_k49))"
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential_14\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_43 (Dense)             (None, 128)               100480    \n_________________________________________________________________\ndense_44 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_45 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_46 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_47 (Dense)             (None, 49)                6321      \n=================================================================\nTotal params: 156,337\nTrainable params: 156,337\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "model_1_2_k49.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_2_k49 test loss: 0.9938585758209229\nmodel_1_2_k49 test accuracy 0.8113471865653992\n"
                }
            ],
            "source": "score = model_1_2_k49.evaluate(test_images_k49, test_labels_k49, verbose=0)\nprint('model_1_2_k49 test loss:', score[0])\nprint('model_1_2_k49 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5_k49 def\n\nmodel_1_5_k49 = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(49, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_5_k49 compile\n\nmodel_1_5_k49.compile(optimizer='sgd',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n5810/5810 [==============================] - 21s 4ms/step - loss: 2.6352 - accuracy: 0.3462 - val_loss: 1.1710 - val_accuracy: 0.6892\nEpoch 2/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 1.0330 - accuracy: 0.7303 - val_loss: 1.0079 - val_accuracy: 0.7305\nEpoch 3/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.7628 - accuracy: 0.7966 - val_loss: 0.6947 - val_accuracy: 0.8121\nEpoch 4/20\n5810/5810 [==============================] - 19s 3ms/step - loss: 0.6233 - accuracy: 0.8309 - val_loss: 0.6231 - val_accuracy: 0.8309\nEpoch 5/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.5449 - accuracy: 0.8506 - val_loss: 0.6295 - val_accuracy: 0.8262\nEpoch 6/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.4840 - accuracy: 0.8665 - val_loss: 0.5403 - val_accuracy: 0.8510\nEpoch 7/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.4447 - accuracy: 0.8773 - val_loss: 0.5401 - val_accuracy: 0.8514\nEpoch 8/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.4098 - accuracy: 0.8867 - val_loss: 0.4804 - val_accuracy: 0.8681\nEpoch 9/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.3785 - accuracy: 0.8940 - val_loss: 0.4610 - val_accuracy: 0.8732\nEpoch 10/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.3554 - accuracy: 0.9002 - val_loss: 0.4448 - val_accuracy: 0.8798\nEpoch 11/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.3326 - accuracy: 0.9070 - val_loss: 0.4586 - val_accuracy: 0.8750\nEpoch 12/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.3158 - accuracy: 0.9113 - val_loss: 0.5064 - val_accuracy: 0.8636\nEpoch 13/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2987 - accuracy: 0.9156 - val_loss: 0.4452 - val_accuracy: 0.8785\nEpoch 14/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2822 - accuracy: 0.9204 - val_loss: 0.5015 - val_accuracy: 0.8645\nEpoch 15/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2683 - accuracy: 0.9242 - val_loss: 0.4251 - val_accuracy: 0.8858\nEpoch 16/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2592 - accuracy: 0.9261 - val_loss: 0.4898 - val_accuracy: 0.8695\nEpoch 17/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2452 - accuracy: 0.9299 - val_loss: 0.5704 - val_accuracy: 0.8511\nEpoch 18/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2343 - accuracy: 0.9324 - val_loss: 0.4461 - val_accuracy: 0.8793\nEpoch 19/20\n5810/5810 [==============================] - 20s 3ms/step - loss: 0.2255 - accuracy: 0.9360 - val_loss: 0.4174 - val_accuracy: 0.8902\nEpoch 20/20\n5810/5810 [==============================] - 19s 3ms/step - loss: 0.2164 - accuracy: 0.9376 - val_loss: 0.4592 - val_accuracy: 0.8805\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8afc7d1290>"
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_5_k49 fit\n\nmodel_1_5_k49.fit(train_images_k49, train_labels_k49, epochs=20, verbose=1, validation_data=(val_images_k49, val_labels_k49))"
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential_15\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_48 (Dense)             (None, 128)               100480    \n_________________________________________________________________\ndense_49 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_50 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_51 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_52 (Dense)             (None, 49)                6321      \n=================================================================\nTotal params: 156,337\nTrainable params: 156,337\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "# model_1_5_k49 summary\n\nmodel_1_5_k49.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_5_k49 test loss: 0.816804826259613\nmodel_1_5_k49 test accuracy 0.8062105774879456\n"
                }
            ],
            "source": "score = model_1_5_k49.evaluate(test_images_k49, test_labels_k49, verbose=0)\nprint('model_1_5_k49 test loss:', score[0])\nprint('model_1_5_k49 test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": "# model_2_k49 def\n\nbatch_size = 128\nnum_classes = 49       #  here we specify the number of classes as 49 instead of 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\nx_train = train_images_k49\nx_test = val_images_k49\ny_train = train_labels_k49\ny_test = val_labels_k49\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nmodel_2_k49 = tf.keras.Sequential()\nmodel_2_k49.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_k49.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_k49.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_k49.add(Dropout(0.25))\nmodel_2_k49.add(tf.keras.layers.Flatten())\nmodel_2_k49.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_k49.add(Dropout(0.5))\nmodel_2_k49.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\n# model_2 compile\n\nmodel_2_k49.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n1453/1453 [==============================] - 35s 24ms/step - loss: 1.5676 - accuracy: 0.5959 - val_loss: 0.3749 - val_accuracy: 0.8997\nEpoch 2/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.6198 - accuracy: 0.8294 - val_loss: 0.2787 - val_accuracy: 0.9261\nEpoch 3/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.4766 - accuracy: 0.8671 - val_loss: 0.2322 - val_accuracy: 0.9376\nEpoch 4/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.4051 - accuracy: 0.8848 - val_loss: 0.2144 - val_accuracy: 0.9422\nEpoch 5/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3549 - accuracy: 0.8969 - val_loss: 0.1954 - val_accuracy: 0.9470\nEpoch 6/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3268 - accuracy: 0.9057 - val_loss: 0.1901 - val_accuracy: 0.9488\nEpoch 7/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3124 - accuracy: 0.9084 - val_loss: 0.1830 - val_accuracy: 0.9513\nEpoch 8/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.2810 - accuracy: 0.9176 - val_loss: 0.1759 - val_accuracy: 0.9531\nEpoch 9/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.2708 - accuracy: 0.9195 - val_loss: 0.1798 - val_accuracy: 0.9523\nEpoch 10/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.2608 - accuracy: 0.9215 - val_loss: 0.1710 - val_accuracy: 0.9544\nEpoch 11/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.2423 - accuracy: 0.9278 - val_loss: 0.1682 - val_accuracy: 0.9551\nEpoch 12/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.2307 - accuracy: 0.9302 - val_loss: 0.1693 - val_accuracy: 0.9554\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8afc6e45d0>"
                    },
                    "execution_count": 80,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model2_k49\n\nmodel_2_k49.fit(x_train, y_train,\n         batch_size=batch_size,\n         epochs=epochs,\n         verbose=1,\n         validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# ***** MISSING EVAL"
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [],
            "source": "# model_2_1_k49 def\n\nmodel_2_1_k49 = tf.keras.Sequential()\nmodel_2_1_k49.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_1_k49.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_2_1_k49.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_1_k49.add(Dropout(0.25))\nmodel_2_1_k49.add(tf.keras.layers.Flatten())\nmodel_2_1_k49.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel_2_1_k49.add(Dropout(0.5))\nmodel_2_1_k49.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": "# change of optimizer and compile model_2_k49\n\nmodel_2_1_k49.compile(loss='sparse_categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0),\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n1453/1453 [==============================] - 20s 13ms/step - loss: 1.5784 - accuracy: 0.5954 - val_loss: 0.4075 - val_accuracy: 0.8927\nEpoch 2/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.5872 - accuracy: 0.8411 - val_loss: 0.2867 - val_accuracy: 0.9230\nEpoch 3/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.4668 - accuracy: 0.8732 - val_loss: 0.2499 - val_accuracy: 0.9323\nEpoch 4/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.4022 - accuracy: 0.8893 - val_loss: 0.2483 - val_accuracy: 0.9370\nEpoch 5/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3721 - accuracy: 0.8983 - val_loss: 0.2283 - val_accuracy: 0.9383\nEpoch 6/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3512 - accuracy: 0.9024 - val_loss: 0.2099 - val_accuracy: 0.9429\nEpoch 7/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3358 - accuracy: 0.9082 - val_loss: 0.2059 - val_accuracy: 0.9437\nEpoch 8/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3320 - accuracy: 0.9099 - val_loss: 0.2138 - val_accuracy: 0.9440\nEpoch 9/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3208 - accuracy: 0.9134 - val_loss: 0.1960 - val_accuracy: 0.9474\nEpoch 10/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3160 - accuracy: 0.9149 - val_loss: 0.1990 - val_accuracy: 0.9471\nEpoch 11/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3166 - accuracy: 0.9150 - val_loss: 0.2488 - val_accuracy: 0.9472\nEpoch 12/12\n1453/1453 [==============================] - 19s 13ms/step - loss: 0.3137 - accuracy: 0.9167 - val_loss: 0.1910 - val_accuracy: 0.9494\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8afc5057d0>"
                    },
                    "execution_count": 83,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model_2_k49 after change of optmizer\n\nmodel_2_1_k49.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n           verbose=1,\n           validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_16 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-84-1365f68752b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2_k49\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_k49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_k49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_k49 test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_k49 test accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_16 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n"
                    ]
                }
            ],
            "source": "score = model_2_k49.evaluate(test_images_k49, test_labels_k49, verbose=0)\nprint('model_2_k49 test loss:', score[0])\nprint('model_2_k49 test accuracy', score[1])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model:  K Nearest Neighbors - k49"
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [],
            "source": "# recall that the two numpy image arrays used below, namely x_train_k49 and x_test_k49\n# are arrays of integers, which works fine for KNN"
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fit KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n"
                },
                {
                    "data": {
                        "text/plain": "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
                    },
                    "execution_count": 86,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "x_train_k49 = load('k49-train-imgs.npz')\ny_train_k49 = load('k49-train-labels.npz')\nx_test_k49 = load('k49-test-imgs.npz')\ny_test_k49 = load('k49-test-labels.npz')\n\nx_train_k49 = x_train_k49.reshape(-1, 784)\nx_test_k49 = x_test_k49.reshape(-1, 784)\n\nmodel_0_k49 = KNeighborsClassifier(n_neighbors=4, weights='distance', n_jobs=-1)\nprint('Fit', model_0_k49)\nmodel_0_k49.fit(x_train_k49, y_train_k49)"
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Evaluate KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\nThe accuracy is: 0.8551638259786754\n"
                }
            ],
            "source": "print('Evaluate', model_0_k49)\nscore = model_0_k49.score(x_test_k49, y_test_k49)\nprint('The accuracy is:', score)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The Third Dataset\n\n#### Includes Kanji characters, this data has 3832 different classes and consists of 140,426 images, each image is 64 X 64 pixels\n#### This dataset is not as processed as the other two. It is just a bunch of png images in a directory inside an archive file."
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2021-07-02 21:51:42--  http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar?raw=True\nResolving codh.rois.ac.jp (codh.rois.ac.jp)... 136.187.88.58\nConnecting to codh.rois.ac.jp (codh.rois.ac.jp)|136.187.88.58|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 324290560 (309M) [application/x-tar]\nSaving to: \u2018kkanji.tar?raw=True\u2019\n\nkkanji.tar?raw=True 100%[===================>] 309.27M  5.09MB/s    in 60s     \n\n2021-07-02 21:52:43 (5.19 MB/s) - \u2018kkanji.tar?raw=True\u2019 saved [324290560/324290560]\n\n-rw-rw---- 1 wsuser watsonstudio 310M Dec  8  2018 kkanji.tar\nkkanji2/\nkkanji2/U+5B87/\nkkanji2/U+5B87/72d56fcb33d10fe0.png\nkkanji2/U+5B87/75f7923797777c74.png\nkkanji2/U+5B87/69d6becd4f8f2d61.png\nkkanji2/U+5B87/522dd01c5f9573f5.png\nkkanji2/U+5B87/36aadd8d92c64049.png\nkkanji2/U+5B87/58f75629e53b9e63.png\nkkanji2/U+5B87/557950fbb39b019b.png\nkkanji2/U+5B87/c4ca643dbc0299b6.png\nkkanji2/U+5B87/02f161e7e7a3c364.png\nkkanji2/U+5B87/c45553bb4a35c8d4.png\nkkanji2/U+5B87/ffa955bd6cb43af8.png\nkkanji2/U+5B87/d0387f14448f2a95.png\nkkanji2/U+5B87/d8c4a0dbd99fc02f.png\nkkanji2/U+5B87/419beef7f2c593da.png\nkkanji2/U+5B87/f2308287339f973d.png\nkkanji2/U+5B87/f885e3a957b99e8e.png\nkkanji2/U+5B87/f5e7a417e3d831d8.png\nkkanji2/U+5B87/17681a9b66db23e0.png\nkkanji2/U+5B87/cc2b8cd01c984262.png\nkkanji2/U+5B87/3e76b512ef42c8f2.png\nkkanji2/U+5B87/49276561d0ca08e0.png\nkkanji2/U+5B87/a169cf27462e020d.png\nkkanji2/U+5B87/61b85600b3fdbea9.png\nkkanji2/U+5B87/112b17b885fbfa61.png\nkkanji2/U+5B87/99654e0e2e597032.png\nkkanji2/U+5B87/7af7faf202121801.png\nkkanji2/U+5B87/8a6b7ea64d025e6d.png\nkkanji2/U+5B87/3c965132ab259d2b.png\nkkanji2/U+5B87/e5e120e4a9d70b6b.png\nkkanji2/U+5B87/a83b76ab3c9ab31c.png\nkkanji2/U+5B87/5a3cf89898fb6100.png\nkkanji2/U+5B87/d84ddc102e8425b6.png\nkkanji2/U+5B87/bdf7cd68b0df8857.png\nkkanji2/U+5B87/a0a4815c3bfe9f15.png\nkkanji2/U+5B87/b2e74a3d92ef78ac.png\nkkanji2/U+5B87/25e9d668d9b64914.png\nkkanji2/U+5B87/5b6ee9b9d03fc3ad.png\nkkanji2/U+583A/\nkkanji2/U+583A/2adaddcb1db613b1.png\nkkanji2/U+583A/3bd7379e66373395.png\nkkanji2/U+583A/ea8dd8f0d7375e9c.png\nkkanji2/U+583A/f738049a58a97177.png\nkkanji2/U+583A/b3a041d6510720b2.png\nkkanji2/U+583A/3921ca3a71dcaaff.png\nkkanji2/U+583A/21d02bce1618fd05.png\nkkanji2/U+583A/df87ce26b03e824d.png\nkkanji2/U+583A/5e5b7454b683e6b0.png\nkkanji2/U+583A/10063d313e1474aa.png\nkkanji2/U+583A/84e528c1a87102b4.png\nkkanji2/U+583A/f8db9187baf4b352.png\nkkanji2/U+583A/e1eb722d60ac207c.png\nkkanji2/U+583A/ab464d2670b260bc.png\nkkanji2/U+583A/596e410f8ae20a07.png\nkkanji2/U+583A/805fa5f10779d104.png\nkkanji2/U+583A/66e27da7a955f8ea.png\nkkanji2/U+583A/d43d5197995e7345.png\nkkanji2/U+583A/0ceea4b4033e6c66.png\nkkanji2/U+5ECA/\nkkanji2/U+5ECA/47d36e0f7df9b8ab.png\nkkanji2/U+5ECA/ea6adb0abe33425c.png\nkkanji2/U+5ECA/542e3b1950722456.png\nkkanji2/U+5ECA/3b16e7bcc8a3a717.png\nkkanji2/U+5ECA/7f899bc5008c5824.png\nkkanji2/U+9CF6/\nkkanji2/U+9CF6/e52af171049817f9.png\nkkanji2/U+9CF6/3a09e6488fd81fcd.png\nkkanji2/U+9CF6/ae5f75bd30a73375.png\nkkanji2/U+5A9B/\ntar: write error\n"
                }
            ],
            "source": "# we download the archive:\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar?raw=True\n!mv kkanji.tar?raw=True kkanji.tar\n!ls -lahr kkanji.tar\n\n# list the contents of the archive\n# limit output to the first 70 files\n\n!tar -tf kkanji.tar | head -70"
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [],
            "source": "# extract the archive:\n!tar -xf kkanji.tar"
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [],
            "source": "# put the codepoints in a file\n# let the first line of the file be name\n# of the column in the dataframe we are creating\n!echo codepoint > codepoints.csv\n!ls kkanji2 >> codepoints.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/home/wsuser/work/codepoints.csv\n"
                }
            ],
            "source": "# verify the file's path:\nprint (os.path.abspath(\"codepoints.csv\"))"
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>codepoint</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U+241C6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U+24FA3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U+25DA1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U+27752</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U+29780</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3827</th>\n      <td>U+FA38</td>\n    </tr>\n    <tr>\n      <th>3828</th>\n      <td>U+FA45</td>\n    </tr>\n    <tr>\n      <th>3829</th>\n      <td>U+FA4A</td>\n    </tr>\n    <tr>\n      <th>3830</th>\n      <td>U+FA55</td>\n    </tr>\n    <tr>\n      <th>3831</th>\n      <td>U+FA5C</td>\n    </tr>\n  </tbody>\n</table>\n<p>3832 rows \u00d7 1 columns</p>\n</div>",
                        "text/plain": "     codepoint\n0      U+241C6\n1      U+24FA3\n2      U+25DA1\n3      U+27752\n4      U+29780\n...        ...\n3827    U+FA38\n3828    U+FA45\n3829    U+FA4A\n3830    U+FA55\n3831    U+FA5C\n\n[3832 rows x 1 columns]"
                    },
                    "execution_count": 92,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# read all the lines of the file into pandas dataframe\n# including the column header which is already in the file\n# display new dataframe\n# here we can confirm that the data has 3832 classes\n\ndf_kanji_classmap = pd.read_csv(\"codepoints.csv\")\ndf_kanji_classmap"
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "# we'll need to read the images in to transform them\n#read the first listed image in the first folder and display it\nimg = mping.imread('kkanji2/U+5B87/72d56fcb33d10fe0.png')\nplt.imshow(img)\nplt.show()\n# note that this image in only \"first\" as listed from the tar arcive above\n# it is not \"first\" in terms of the codepoint listing we created directly above"
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [],
            "source": "# create a pandas dataframe that contains the codepoint for each image, \n# and its full path in the os and display that dataframe\n\n#  ** reminder:  makes sure to set the path line correctly using the fact that\n# the directory kkanji2 is in the same directory as the file codepoints.csv\n\ndata = []\ndir = os.path.realpath('/home/wsuser/work/kkanji2')\nfor r, d, f in os.walk(dir):\n    for file in f:\n        if \".png\" in file:\n            data.append((r.split('/')[-1],os.path.join(r,file)))\ndf_kanji2 = pd.DataFrame(data, columns=['codepoint', 'image_file_path']).sort_values(by=['codepoint'], ignore_index = True)"
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>codepoint</th>\n      <th>image_file_path</th>\n      <th>np_array</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U+241C6</td>\n      <td>/home/wsuser/work/kkanji2/U+241C6/c0d603c6ce4a...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U+241C6</td>\n      <td>/home/wsuser/work/kkanji2/U+241C6/689fa55040ec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U+24FA3</td>\n      <td>/home/wsuser/work/kkanji2/U+24FA3/4190e728bfc9...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U+24FA3</td>\n      <td>/home/wsuser/work/kkanji2/U+24FA3/80582798ed70...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U+25DA1</td>\n      <td>/home/wsuser/work/kkanji2/U+25DA1/512d7fcacddd...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140419</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/093ab4bc62fab...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>140420</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/f03dee341d017...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>140421</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/e837b009ba51d...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>140422</th>\n      <td>U+FA5C</td>\n      <td>/home/wsuser/work/kkanji2/U+FA5C/15e2060396eba...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>140423</th>\n      <td>U+FA5C</td>\n      <td>/home/wsuser/work/kkanji2/U+FA5C/679e4b2f026f6...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>140424 rows \u00d7 3 columns</p>\n</div>",
                        "text/plain": "       codepoint                                    image_file_path np_array\n0        U+241C6  /home/wsuser/work/kkanji2/U+241C6/c0d603c6ce4a...         \n1        U+241C6  /home/wsuser/work/kkanji2/U+241C6/689fa55040ec...         \n2        U+24FA3  /home/wsuser/work/kkanji2/U+24FA3/4190e728bfc9...         \n3        U+24FA3  /home/wsuser/work/kkanji2/U+24FA3/80582798ed70...         \n4        U+25DA1  /home/wsuser/work/kkanji2/U+25DA1/512d7fcacddd...         \n...          ...                                                ...      ...\n140419    U+FA55  /home/wsuser/work/kkanji2/U+FA55/093ab4bc62fab...         \n140420    U+FA55  /home/wsuser/work/kkanji2/U+FA55/f03dee341d017...         \n140421    U+FA55  /home/wsuser/work/kkanji2/U+FA55/e837b009ba51d...         \n140422    U+FA5C  /home/wsuser/work/kkanji2/U+FA5C/15e2060396eba...         \n140423    U+FA5C  /home/wsuser/work/kkanji2/U+FA5C/679e4b2f026f6...         \n\n[140424 rows x 3 columns]"
                    },
                    "execution_count": 95,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# add a blank column to the dataframe with column name 'np_array'\n\ndf_kanji2['np_array'] = \"\"\ndf_kanji2"
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [],
            "source": "# convert the pandas dataframe into a pyspark dataframe\ndf_kanji2_pyspk = spark.createDataFrame(df_kanji2)"
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---------+--------------------+--------+----------+\n|codepoint|     image_file_path|np_array|classIndex|\n+---------+--------------------+--------+----------+\n|  U+241C6|/home/wsuser/work...|        |    2606.0|\n|  U+241C6|/home/wsuser/work...|        |    2606.0|\n|  U+24FA3|/home/wsuser/work...|        |    2607.0|\n|  U+24FA3|/home/wsuser/work...|        |    2607.0|\n|  U+25DA1|/home/wsuser/work...|        |    3017.0|\n|  U+27752|/home/wsuser/work...|        |    1966.0|\n|  U+27752|/home/wsuser/work...|        |    1966.0|\n|  U+27752|/home/wsuser/work...|        |    1966.0|\n|  U+27752|/home/wsuser/work...|        |    1966.0|\n|  U+27752|/home/wsuser/work...|        |    1966.0|\n|  U+29780|/home/wsuser/work...|        |    3018.0|\n|  U+29DDA|/home/wsuser/work...|        |    3019.0|\n|  U+29E75|/home/wsuser/work...|        |    3020.0|\n|   U+4093|/home/wsuser/work...|        |    3021.0|\n|   U+4453|/home/wsuser/work...|        |     680.0|\n|   U+4453|/home/wsuser/work...|        |     680.0|\n|   U+4453|/home/wsuser/work...|        |     680.0|\n|   U+4453|/home/wsuser/work...|        |     680.0|\n|   U+4453|/home/wsuser/work...|        |     680.0|\n|   U+4453|/home/wsuser/work...|        |     680.0|\n+---------+--------------------+--------+----------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "# our data has 3,831 different classes each with unique string names\n# which is based on their character codepoints\n# but we want simple numeric class index\n# so we instantiate a StringIndexer in spark:\n\nindexer = StringIndexer(inputCol=\"codepoint\",outputCol=\"classIndex\")\nindexed_df = indexer.fit(df_kanji2_pyspk).transform(df_kanji2_pyspk)\nindexed_df.show()"
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>codepoint</th>\n      <th>image_file_path</th>\n      <th>np_array</th>\n      <th>classIndex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U+241C6</td>\n      <td>/home/wsuser/work/kkanji2/U+241C6/c0d603c6ce4a...</td>\n      <td></td>\n      <td>2606.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U+241C6</td>\n      <td>/home/wsuser/work/kkanji2/U+241C6/689fa55040ec...</td>\n      <td></td>\n      <td>2606.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U+24FA3</td>\n      <td>/home/wsuser/work/kkanji2/U+24FA3/4190e728bfc9...</td>\n      <td></td>\n      <td>2607.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U+24FA3</td>\n      <td>/home/wsuser/work/kkanji2/U+24FA3/80582798ed70...</td>\n      <td></td>\n      <td>2607.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U+25DA1</td>\n      <td>/home/wsuser/work/kkanji2/U+25DA1/512d7fcacddd...</td>\n      <td></td>\n      <td>3017.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140419</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/093ab4bc62fab...</td>\n      <td></td>\n      <td>1041.0</td>\n    </tr>\n    <tr>\n      <th>140420</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/f03dee341d017...</td>\n      <td></td>\n      <td>1041.0</td>\n    </tr>\n    <tr>\n      <th>140421</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/e837b009ba51d...</td>\n      <td></td>\n      <td>1041.0</td>\n    </tr>\n    <tr>\n      <th>140422</th>\n      <td>U+FA5C</td>\n      <td>/home/wsuser/work/kkanji2/U+FA5C/15e2060396eba...</td>\n      <td></td>\n      <td>3016.0</td>\n    </tr>\n    <tr>\n      <th>140423</th>\n      <td>U+FA5C</td>\n      <td>/home/wsuser/work/kkanji2/U+FA5C/679e4b2f026f6...</td>\n      <td></td>\n      <td>3016.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>140424 rows \u00d7 4 columns</p>\n</div>",
                        "text/plain": "       codepoint                                    image_file_path np_array  \\\n0        U+241C6  /home/wsuser/work/kkanji2/U+241C6/c0d603c6ce4a...            \n1        U+241C6  /home/wsuser/work/kkanji2/U+241C6/689fa55040ec...            \n2        U+24FA3  /home/wsuser/work/kkanji2/U+24FA3/4190e728bfc9...            \n3        U+24FA3  /home/wsuser/work/kkanji2/U+24FA3/80582798ed70...            \n4        U+25DA1  /home/wsuser/work/kkanji2/U+25DA1/512d7fcacddd...            \n...          ...                                                ...      ...   \n140419    U+FA55  /home/wsuser/work/kkanji2/U+FA55/093ab4bc62fab...            \n140420    U+FA55  /home/wsuser/work/kkanji2/U+FA55/f03dee341d017...            \n140421    U+FA55  /home/wsuser/work/kkanji2/U+FA55/e837b009ba51d...            \n140422    U+FA5C  /home/wsuser/work/kkanji2/U+FA5C/15e2060396eba...            \n140423    U+FA5C  /home/wsuser/work/kkanji2/U+FA5C/679e4b2f026f6...            \n\n        classIndex  \n0           2606.0  \n1           2606.0  \n2           2607.0  \n3           2607.0  \n4           3017.0  \n...            ...  \n140419      1041.0  \n140420      1041.0  \n140421      1041.0  \n140422      3016.0  \n140423      3016.0  \n\n[140424 rows x 4 columns]"
                    },
                    "execution_count": 98,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# transform back to pandas dataframe:\ndf_kanji2 = indexed_df.toPandas()\ndf_kanji2"
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [],
            "source": "# add a column containing and numpy array of the image indicated in the path in image_file_path\n# and at the same time, flatten each image from a 64 x 64 numpy array to a single\n# dimension 4096 element long numpy array\ndf_kanji2['np_array'] = df_kanji2['image_file_path'].apply(lambda x: np.asarray(Image.open(x))).apply(lambda y: np.reshape(y,(4096,)))"
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>codepoint</th>\n      <th>image_file_path</th>\n      <th>np_array</th>\n      <th>classIndex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U+241C6</td>\n      <td>/home/wsuser/work/kkanji2/U+241C6/c0d603c6ce4a...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>2606.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U+241C6</td>\n      <td>/home/wsuser/work/kkanji2/U+241C6/689fa55040ec...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>2606.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U+24FA3</td>\n      <td>/home/wsuser/work/kkanji2/U+24FA3/4190e728bfc9...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>2607.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U+24FA3</td>\n      <td>/home/wsuser/work/kkanji2/U+24FA3/80582798ed70...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>2607.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U+25DA1</td>\n      <td>/home/wsuser/work/kkanji2/U+25DA1/512d7fcacddd...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>3017.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140419</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/093ab4bc62fab...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1041.0</td>\n    </tr>\n    <tr>\n      <th>140420</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/f03dee341d017...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1041.0</td>\n    </tr>\n    <tr>\n      <th>140421</th>\n      <td>U+FA55</td>\n      <td>/home/wsuser/work/kkanji2/U+FA55/e837b009ba51d...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1041.0</td>\n    </tr>\n    <tr>\n      <th>140422</th>\n      <td>U+FA5C</td>\n      <td>/home/wsuser/work/kkanji2/U+FA5C/15e2060396eba...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>3016.0</td>\n    </tr>\n    <tr>\n      <th>140423</th>\n      <td>U+FA5C</td>\n      <td>/home/wsuser/work/kkanji2/U+FA5C/679e4b2f026f6...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>3016.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>140424 rows \u00d7 4 columns</p>\n</div>",
                        "text/plain": "       codepoint                                    image_file_path  \\\n0        U+241C6  /home/wsuser/work/kkanji2/U+241C6/c0d603c6ce4a...   \n1        U+241C6  /home/wsuser/work/kkanji2/U+241C6/689fa55040ec...   \n2        U+24FA3  /home/wsuser/work/kkanji2/U+24FA3/4190e728bfc9...   \n3        U+24FA3  /home/wsuser/work/kkanji2/U+24FA3/80582798ed70...   \n4        U+25DA1  /home/wsuser/work/kkanji2/U+25DA1/512d7fcacddd...   \n...          ...                                                ...   \n140419    U+FA55  /home/wsuser/work/kkanji2/U+FA55/093ab4bc62fab...   \n140420    U+FA55  /home/wsuser/work/kkanji2/U+FA55/f03dee341d017...   \n140421    U+FA55  /home/wsuser/work/kkanji2/U+FA55/e837b009ba51d...   \n140422    U+FA5C  /home/wsuser/work/kkanji2/U+FA5C/15e2060396eba...   \n140423    U+FA5C  /home/wsuser/work/kkanji2/U+FA5C/679e4b2f026f6...   \n\n                                                 np_array  classIndex  \n0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2606.0  \n1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2606.0  \n2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2607.0  \n3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2607.0  \n4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      3017.0  \n...                                                   ...         ...  \n140419  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      1041.0  \n140420  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      1041.0  \n140421  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      1041.0  \n140422  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      3016.0  \n140423  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      3016.0  \n\n[140424 rows x 4 columns]"
                    },
                    "execution_count": 100,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_kanji2"
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [],
            "source": "# take the np_array and classIndex columns out of the dataframe and put them into two numpy arrays\nimages_kanji = df_kanji2[\"np_array\"].to_numpy()\nlabels_kanji = df_kanji2[\"classIndex\"].to_numpy()"
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [],
            "source": "# at this point, the images are stored in a numpy array containing numpy arrays for each each, but instead\n# we want a two dimensional numpy array, so convert that as follows\nimages_kanji = np.stack(images_kanji)"
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(140424, 4096)"
                    },
                    "execution_count": 103,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "images_kanji.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(140424,)"
                    },
                    "execution_count": 104,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "labels_kanji.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {},
            "outputs": [],
            "source": "# now that the image and label arrays have the right dimensions, \n# we need to divide them into training, validation, and test sets:\n\nx_train_kanji, x_test_kanji, y_train_kanji, y_test_kanji = train_test_split(images_kanji, labels_kanji, test_size = 0.2, random_state=42)\nx_train_kanji, x_val_kanji, y_train_kanji, y_val_kanji = train_test_split(x_train_kanji, y_train_kanji, test_size = 0.2, random_state=28)"
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {},
            "outputs": [],
            "source": "# we need to normalize each of the training and test image numpy arrays so that each number in the numpy\n# array is between 0 and 1:\n\nx_train_kanji =  x_train_kanji / 255\nx_test_kanji = x_test_kanji / 255\nx_val_kanji = x_val_kanji / 255"
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2_k def\n\nmodel_1_2_k = tf.keras.Sequential([\n    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n    tf.keras.layers.Dense(1024, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n    tf.keras.layers.Dense(1024, activation=tf.nn.relu),    \n    tf.keras.layers.Dense(3832, activation=tf.nn.softmax)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [],
            "source": "# model_1_2_k compile\nmodel_1_2_k.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/20\n2809/2809 [==============================] - 26s 9ms/step - loss: 5.4430 - accuracy: 0.1814 - val_loss: 3.8729 - val_accuracy: 0.3508\nEpoch 2/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 3.3847 - accuracy: 0.3924 - val_loss: 3.4035 - val_accuracy: 0.4237\nEpoch 3/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 2.7520 - accuracy: 0.4693 - val_loss: 3.3251 - val_accuracy: 0.4562\nEpoch 4/20\n2809/2809 [==============================] - 26s 9ms/step - loss: 2.3661 - accuracy: 0.5229 - val_loss: 3.2626 - val_accuracy: 0.4744\nEpoch 5/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 2.1251 - accuracy: 0.5528 - val_loss: 3.2481 - val_accuracy: 0.4820\nEpoch 6/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.9293 - accuracy: 0.5812 - val_loss: 3.3912 - val_accuracy: 0.4891\nEpoch 7/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.7918 - accuracy: 0.6028 - val_loss: 3.4771 - val_accuracy: 0.4904\nEpoch 8/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.7049 - accuracy: 0.6174 - val_loss: 3.7173 - val_accuracy: 0.4980\nEpoch 9/20\n2809/2809 [==============================] - 26s 9ms/step - loss: 1.6255 - accuracy: 0.6320 - val_loss: 3.7000 - val_accuracy: 0.4974\nEpoch 10/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.5617 - accuracy: 0.6402 - val_loss: 3.9172 - val_accuracy: 0.4982\nEpoch 11/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.4897 - accuracy: 0.6541 - val_loss: 4.0353 - val_accuracy: 0.4943\nEpoch 12/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.4704 - accuracy: 0.6590 - val_loss: 4.0323 - val_accuracy: 0.5013\nEpoch 13/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.4244 - accuracy: 0.6687 - val_loss: 4.2674 - val_accuracy: 0.5006\nEpoch 14/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.4331 - accuracy: 0.6685 - val_loss: 4.3925 - val_accuracy: 0.4975\nEpoch 15/20\n2809/2809 [==============================] - 26s 9ms/step - loss: 1.3898 - accuracy: 0.6772 - val_loss: 4.4749 - val_accuracy: 0.4999\nEpoch 16/20\n2809/2809 [==============================] - 26s 9ms/step - loss: 1.3866 - accuracy: 0.6781 - val_loss: 4.4981 - val_accuracy: 0.4965\nEpoch 17/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.3509 - accuracy: 0.6867 - val_loss: 4.6075 - val_accuracy: 0.4899\nEpoch 18/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.3724 - accuracy: 0.6848 - val_loss: 4.8141 - val_accuracy: 0.4938\nEpoch 19/20\n2809/2809 [==============================] - 26s 9ms/step - loss: 1.3495 - accuracy: 0.6891 - val_loss: 4.8556 - val_accuracy: 0.4931\nEpoch 20/20\n2809/2809 [==============================] - 25s 9ms/step - loss: 1.3427 - accuracy: 0.6916 - val_loss: 4.9066 - val_accuracy: 0.4869\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8bec16c890>"
                    },
                    "execution_count": 109,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# model_1_2_k fit\nmodel_1_2_k.fit(x_train_kanji, y_train_kanji, epochs=20, verbose=1, validation_data=(x_val_kanji, y_val_kanji))"
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "model_1_2_k test loss: 4.8285813331604\nmodel_1_2_k test accuracy 0.49211323261260986\n"
                }
            ],
            "source": "score = model_1_2_k.evaluate(x_test_kanji, y_test_kanji, verbose=0)\nprint('model_1_2_k test loss:', score[0])\nprint('model_1_2_k test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {},
            "outputs": [],
            "source": "# model_2_k def\n\nbatch_size = 128\nnum_classes = 3832       #  here we specify the number of classes as 3832 instead of 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 64, 64"
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [],
            "source": "x_train = x_train_kanji\nx_test = x_val_kanji\ny_train = y_train_kanji\ny_test = y_val_kanji"
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [],
            "source": "if K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)"
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {},
            "outputs": [],
            "source": "model_2_k = tf.keras.Sequential()\nmodel_2_k.add(Conv2D(64, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel_2_k.add(Conv2D(128, (3, 3), activation='relu'))\nmodel_2_k.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2_k.add(Dropout(0.25))\nmodel_2_k.add(tf.keras.layers.Flatten())\nmodel_2_k.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel_2_k.add(Dropout(0.5))\nmodel_2_k.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {},
            "outputs": [],
            "source": "# model_2 compile\n\nmodel_2_k.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/12\n703/703 [==============================] - 148s 182ms/step - loss: 5.6605 - accuracy: 0.1998 - val_loss: 3.2154 - val_accuracy: 0.5117\nEpoch 2/12\n703/703 [==============================] - 98s 139ms/step - loss: 3.2156 - accuracy: 0.4659 - val_loss: 2.3920 - val_accuracy: 0.6219\nEpoch 3/12\n703/703 [==============================] - 98s 139ms/step - loss: 2.3398 - accuracy: 0.5682 - val_loss: 1.9916 - val_accuracy: 0.6784\nEpoch 4/12\n703/703 [==============================] - 98s 139ms/step - loss: 1.8214 - accuracy: 0.6344 - val_loss: 1.8038 - val_accuracy: 0.7029\nEpoch 5/12\n703/703 [==============================] - 98s 139ms/step - loss: 1.4584 - accuracy: 0.6835 - val_loss: 1.7308 - val_accuracy: 0.7181\nEpoch 6/12\n703/703 [==============================] - 98s 139ms/step - loss: 1.1592 - accuracy: 0.7294 - val_loss: 1.7409 - val_accuracy: 0.7262\nEpoch 7/12\n703/703 [==============================] - 98s 139ms/step - loss: 0.9564 - accuracy: 0.7629 - val_loss: 1.7245 - val_accuracy: 0.7257\nEpoch 8/12\n703/703 [==============================] - 98s 139ms/step - loss: 0.7950 - accuracy: 0.7926 - val_loss: 1.7964 - val_accuracy: 0.7328\nEpoch 9/12\n703/703 [==============================] - 98s 139ms/step - loss: 0.6816 - accuracy: 0.8158 - val_loss: 1.8444 - val_accuracy: 0.7284\nEpoch 10/12\n703/703 [==============================] - 98s 139ms/step - loss: 0.5849 - accuracy: 0.8362 - val_loss: 1.8512 - val_accuracy: 0.7329\nEpoch 11/12\n703/703 [==============================] - 98s 139ms/step - loss: 0.5183 - accuracy: 0.8524 - val_loss: 1.8703 - val_accuracy: 0.7333\nEpoch 12/12\n703/703 [==============================] - 98s 139ms/step - loss: 0.4710 - accuracy: 0.8639 - val_loss: 1.9149 - val_accuracy: 0.7315\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f88e42b1110>"
                    },
                    "execution_count": 116,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# fit model_2_k\n\nmodel_2_k.fit(x_train, y_train,\n         batch_size=batch_size,\n         epochs=epochs,\n         verbose=1,\n         validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 117,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_19 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 4096)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-117-170b96a02ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_kanji\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_kanji\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_k test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_2_k test accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.7-CUDA/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_19 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 4096)\n"
                    ]
                }
            ],
            "source": "score = model_2_k.evaluate(x_test_kanji, y_test_kanji, verbose=0)\nprint('model_2_k test loss:', score[0])\nprint('model_2_k test accuracy', score[1])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7 + GPU",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}