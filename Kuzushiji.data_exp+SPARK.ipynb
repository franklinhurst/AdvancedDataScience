{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "## Initial Data Exploration Kuzushiji\n\nOnce you've identified a Use Case and Data Set it is time to get familiar with data. In the process model this task is called Initial Data Exploration. Please take a minute or two to (re)visit the following lecture\n\nhttps://www.coursera.org/learn/data-science-methodology\n\nModule 2 - Data Understanding\n\nPlease also revisit:\n\nhttp://coursera.org/learn/ds\n\nModule 3 - Mathematical Foundations and Module 4 - Visualizations\n\nGiven the lectures above, please create statistics and visualization on your Data Set to identify good columns for modeling, potential data quality issues and anticipate potential feature transformations necessary.\n\nCreate a jupyter notebook where you document your code and include visualizations as first deliverable. Please also stick to the naming conventions explained in the the process model manual.\n\nSo, the most important reasons / steps are:\n\nIdentify quality issues (e.g. missing values, wrong measurements, \u2026)\n\nAssess feature quality \u2013 how relevant is a certain measurement (e.g. use correlation matrix)\n\nGet an idea on the value distribution of your data using statistical measures and visualizations"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "!pip install tensorflow\n!pip install seaborn==0.11.1\n!pip install Pillow\n!pip install python-mnist\n!pip install pyspark"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\nimport tensorflow as tf\nimport seaborn as sns\nfrom mnist import MNIST\nimport numpy as np\nimport PIL\nfrom PIL import Image\nimport os\nimport matplotlib.image as mping\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer\nfrom numpy import asarray\nimport pandas as pd"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "tf.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "sns.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "PIL.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "# fire up the spark session\n# remove this for spark environment\n#sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\n#spark = SparkSession \\\n#    .builder \\\n#    .getOrCreate()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "# enable arrow which lets us transfrom a pandas dataframe into a pyspark dataframe\nspark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz?raw=True\n!mv train-images-idx3-ubyte.gz?raw=True train-images-idx3-ubyte.gz\n!gunzip train-images-idx3-ubyte.gz\n!ls -lahr train-images-idx3-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz?raw=True\n!mv train-labels-idx1-ubyte.gz?raw=True train-labels-idx1-ubyte.gz\n!gunzip train-labels-idx1-ubyte.gz\n!ls -lahr train-labels-idx1-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz?raw=True\n!mv t10k-images-idx3-ubyte.gz?raw=True t10k-images-idx3-ubyte.gz\n!gunzip t10k-images-idx3-ubyte.gz\n!ls -lahr t10k-images-idx3-ubyte\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz?raw=True\n!mv t10k-labels-idx1-ubyte.gz?raw=True t10k-labels-idx1-ubyte.gz\n!gunzip t10k-labels-idx1-ubyte.gz\n!ls -lahr t10k-labels-idx1-ubyte"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "url = \"http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist_classmap.csv\"\ndf_classmap = pd.read_csv(url)\ndf_classmap.head(11)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "# let's add the sound the character makes for non-Japanese speakers\n# just to clarify the function of these characters in spoken Japanese\n\nphonetic = ['o','ki','su','tsu','na','ha','ma','ya','re','wo']\ndf_classmap['phonetic'] = phonetic\ndf_classmap"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "!mkdir kmnistdata"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "!ls -al"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "!cp t10k-images-idx3-ubyte kmnistdata/t10k-images-idx3-ubyte\n!cp t10k-labels-idx1-ubyte kmnistdata/t10k-labels-idx1-ubyte\n!cp train-images-idx3-ubyte kmnistdata/train-images-idx3-ubyte\n!cp train-labels-idx1-ubyte kmnistdata/train-labels-idx1-ubyte"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "!ls -al kmnistdata"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\nStill waiting for Spark session to start..\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "data = MNIST('kmnistdata')\ntrain_images, train_labels = data.load_training()\ntest_images, test_labels = data.load_testing()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "print(train_labels[0])\nprint(train_images[0])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "print(train_labels[1])\nprint(train_images[1])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "type(train_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "type(train_images)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "train_labels.typecode"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# the following output is (address, length) giving current memory address\n# and length in elements of the buffer used to hold the array's\n# contents\n\ntrain_labels.buffer_info()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# In the first dataset that we downloaded and loaded above, the data\n# is already flattened, which is good for the machine learning model\n# but we would like to actaully be able to view the images\n\n# so, the first step here is the convert the data into numpy arrays\n# numpy arrays can be used to normalize for the ML model, but also\n# numpy arrays are easier to reshape in case we want to actually view \n# the data as images"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "# transform to numpy arrays\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# now we should be able to do more data exploration\ntrain_images.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# the data is already flattened for use in the model, but\n# we need to unflatten the data if we want to view and verify \n# that these are actually images of kuzushiji characters\n\ntrain_images = np.reshape(train_images, (60000, 28, 28))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# let's see the image at index 0\nplt.figure()\nplt.imshow(train_images[0])\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "df_classmap"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# so we can see, using the classmap that this character \n# pronounced \"re\" should be type number 8\ntrain_labels[0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# we can check another one:\nplt.figure()\nplt.imshow(train_images[5])\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# this one is 'su', so according to the classmap\n# it should be type 2\ntrain_labels[5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nStill waiting for Spark session to start..\n"
                }
            ],
            "source": "# next\nplt.figure()\nplt.imshow(train_images[7])\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\n"
                }
            ],
            "source": "# I cannot visually determine which one it is\n# Checking the type:\ntrain_labels[7]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# next we print the class number, the written character, and the phonetic\n# for index numbers 20 through 40:\nfor i in range(20,40):\n    print(train_labels[i])\n    print(df_classmap.loc[train_labels[i],'char'], df_classmap.loc[train_labels[i],'phonetic'])\n    plt.figure()\n    plt.imshow(train_images[i])\n    plt.show()\n    \n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# So we now we have verified this data is what we want: namely images of kuzushiji characters\n# which we can view in \"unflattned\" format (60000, 28, 28) as images and that we can leave in \"flattened\" \n# format in two dimensional numpy arrays with dimensions (60000, 784) for use in the ML model\n\n# next we convert the train_labels numpy array to a dataframe\n\ndf_train_labels = pd.DataFrame(train_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sns.displot(df_train_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# so shows us this is a balanced set"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_train_labels[0].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# this confirms the set is perfectly balanced"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# next we obtain a slightly more difficult dataset\n# which includes 49 classes of kuzushiji instead of just\n# 10 classes:\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz?raw=True\n!mv k49-train-imgs.npz?raw=True k49-train-imgs.npz\n!ls -lahr k49-train-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz?raw=True\n!mv k49-train-labels.npz?raw=True k49-train-labels.npz\n!ls -lahr k49-train-labels.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz?raw=True\n!mv k49-test-imgs.npz?raw=True k49-test-imgs.npz\n!ls -lahr k49-test-imgs.npz\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz?raw=True\n!mv k49-test-labels.npz?raw=True k49-test-labels.npz\n!ls -lahr k49-test-labels.npz"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# define a load function and use it to load to numpy arrays\n\ndef load(f):\n    return np.load(f)['arr_0']\n\nk49_train_images = load('k49-train-imgs.npz')\nk49_train_labels = load('k49-train-labels.npz')\nk49_test_images = load('k49-test-imgs.npz')\nk49_test_labels = load('k49-test-labels.npz')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# and the class map of the 49 character data set\n\nurl = \"http://codh.rois.ac.jp/kmnist/dataset/k49/k49_classmap.csv\"\ndf_k49_classmap = pd.read_csv(url)\ndf_k49_classmap.head(51)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# let's add the phonetic sound the character makes for clarity\n\nk49_phonetic = ['a', 'i',  'u',  'e',  'o',\\\n                'ka','ki', 'ku', 'ke', 'ko',\\\n                'sa','shi','su', 'se', 'so',\\\n                'ta','chi','tsu','te', 'to',\\\n                'na','ni', 'nu', 'ne', 'no',\\\n                'ha','hi', 'fu', 'he', 'ho',\\\n                'ma','mi', 'mu', 'me', 'mo',\\\n                'ya','yu', 'yo',\\\n                'ra','ri', 'ru', 're', 'ro',\\\n                'wa','wi', 'we ','wo', 'n','iteration_mark']\nprint(len(k49_phonetic))\ndf_k49_classmap['phonetic'] = k49_phonetic\ndf_k49_classmap"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "type(k49_train_images)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k49_train_images.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# this tells us that we have 232,365 images \n# that are each 28 x 28 pixels"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# let's see the image at index 0\nplt.figure()\nplt.imshow(k49_train_images[0])\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# visually, this one look like 'ma'\n# so according to the classmap\n# it should be type 30\nk49_train_labels[0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# let's see the image at index 11\nplt.figure()\nplt.imshow(k49_train_images[11])\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# visually, we can see using the classmap\n# that this one looks like 'no'\n# so according to the classmap\n# it should be type 24\nk49_train_labels[11]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# next we print the class number, the written character, and the phonetic\n# for index numbers 80 through 100:\nfor i in range(80,100):\n    print(k49_train_labels[i])\n    print(df_k49_classmap.loc[k49_train_labels[i],'char'], df_k49_classmap.loc[k49_train_labels[i],'phonetic'])\n    plt.figure()\n    plt.imshow(k49_train_images[i])\n    plt.show()\n    \n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# For the 2nd dataset with 49 classes\n# we now we have verified visually that data is what we want:\n# images of 49 different kuzushiji characters\n\n# next we convert k49_train_labels numpy array to a dataframe\n# in order to inspect the dataset further:\n\ndf_k49_train_labels = pd.DataFrame(k49_train_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# lets see how the character data is distributed among the 49 classes:\nsns.displot(df_k49_train_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_k49_train_labels[0].value_counts().sort_index()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# so we confirm that many of the classes do not have 6,000 in the second data \n# set so the data set is not balanced"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# the final dataset includes Kanji characters\n# this data has 3832 different classes and\n# consists of 140,426 images\n\n# this dataset is not as processed as the other two:\n# it is just a bunch of png images in a directory\n# inside an archive file\n\n# we download the archive:\n\n!wget http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar?raw=True\n!mv kkanji.tar?raw=True kkanji.tar\n!ls -lahr kkanji.tar"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# next, unarchive and set up the numpy arrays\n# for the third (kanji) dataset\n\n# first we'll set up the classmap for the \n# kanji dataset"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# list the contents of the archive\n# limit output to the first 70 files\n\n!tar -tf kkanji.tar | head -70"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# remove the directory of images, so it an be rebuilt\n!rm -rf kkanji2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# checking whats in the current working directory:\n\n!ls -al"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# so the format of the data is that the individual images exist\n# in folders whose names are the codepoint for the image category\n# these folder names will be the basis for the class Index for each image\n\n# next lets extract:\n\n!tar -xf kkanji.tar"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# checking whats in the current working directory:\n\n!ls -al"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# now list out the first 50 folder names in the directory kkanji2\n# the folder names are also the codepoint of each of the characters:\n\n!ls kkanji2 | head -50"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# put the codepoints in a file\n# let the first line of the file be name\n# of the column in the dataframe we are creating\n!echo codepoint > codepoints.csv\n!ls kkanji2 >> codepoints.csv\n!cat codepoints.csv | head -50"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!ls -al"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print (os.path.abspath(\"codepoints.csv\"))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# read all the lines of the file into pandas dataframe\n# including the column header which is already in the file\n\ndf_kanji_classmap = pd.read_csv(\"codepoints.csv\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_kanji_classmap"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#read the first listed image in the first folder and display it\nimg = mping.imread('kkanji2/U+5B87/72d56fcb33d10fe0.png')\nplt.imshow(img)\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# verify the full path for the folder containing the images\npath_var = str(os.path.abspath(\"kkanji2/\"))\npath_var"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create a pandas dataframe that contains the codepoint for each image, \n# and its full path in the os and display that dataframe\n\ndata = []\ndir = os.path.realpath(path_var)\nfor r, d, f in os.walk(dir):\n    for file in f:\n        if \".png\" in file:\n            data.append((r.split('/')[-1],os.path.join(r,file)))\ndf_kanji2 = pd.DataFrame(data, columns=['codepoint', 'image_file_path']).sort_values(by=['codepoint'], ignore_index = True)\ndf_kanji2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# show the os path of the first image\ndf_kanji2['image_file_path'][0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# read the image using Pillow\npimage = Image.open(df_kanji2['image_file_path'][0])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# show some information about the image:\nprint(pimage.format)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(pimage.size)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(pimage.mode)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# it is important to know that the image is 64 x 64 pixels, unlike the first two datasets"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# next read the image using matplotlib"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "img = image.imread(df_kanji2['image_file_path'][0])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(img.dtype)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(img.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.imshow(img)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# next we want to try to convert this image into a numpy array"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "image_nparray = asarray(img)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# verify we have created a numpy array\nprint(type(image_nparray))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# verify the numpy array is the correct dimensions:\nprint(image_nparray.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "image_nparray"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# convert the pandas dataframe into a pyspark dataframe\ndf_kanji2_pyspk = spark.createDataFrame(df_kanji2)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# our data has 3,831 different classes each with unique string names\n# which is based on their character codepoints\n# but we want simple numeric class index\n# so we instantiate a StringIndexer in spark:\n\nindexer = StringIndexer(inputCol=\"codepoint\",outputCol=\"classIndex\")\nindexed_df = indexer.fit(df_kanji2_pyspk).transform(df_kanji2_pyspk)\nindexed_df.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# transform back to pandas dataframe:\ndf_kanji2 = indexed_df.toPandas()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_kanji2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# now it is easy to explore the distribution between the classes:\n# note that the StringIndexer took frequency into account when\n# creating the classes, so the lowest indexes have the largest count:\n\nsns.displot(df_kanji2['classIndex'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_kanji2['classIndex'].value_counts().sort_index()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# walk through the dataframe and display an image and the\n# image's class Index\n\nfor i in range(0,100):\n    print('Dataframe Index: ', i)\n    print('Class Index: ', df_kanji2['classIndex'][i])\n    imag = image.imread(df_kanji2['image_file_path'][i])\n    plt.figure()\n    plt.imshow(imag)\n    plt.show()\n    \n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# so in our exploration of the 3rd dataset, we can see\n# that the data set contains more complex images and \n# that they are larger, and also that this 3rd dataset\n# is also an unbalanced dataset i.e. there are not\n# the same numbers of each class."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "[end]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7 with Spark",
            "language": "python3",
            "name": "python37"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}