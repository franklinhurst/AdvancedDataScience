{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "Functional Programming (FP)\nlambda calculus\nIn functinal programming, every calculation can be expresses as an anonymous function which is applied to a dataset.\nIt is Turing complete, which means that any program can be converted to a functional programming with lambda calculus.\nThe first FP language was LISP in 1950s.  Haskell and Scala are also.  Scala is the most recent example of a FP language.\nScala also supports procedural and object oriented programming.\nPython, R, and Java also support rudimentary FP.  In FP, a function is is treated the same as a constant, variable, or object.\nFunctions can have functions as parameters and can return functions as a result of a call.  A function can return a function.\nA function can even return a function that returns other functions.\n\nWhen we use functional program we can apply a function to a data structure:\n\nf(x) = 1 + x\nlist = [1,2,3,4]\n\nIf we apply a function to a list, that generates another list\n\nanotherList = apply(f(x),list)\n\nanotherlist\n\nResult> [2,3,4,5]\n\nIn procedural programming or OOP, we would need to iterate over the list and perform the calculation a number of times.\n\nIn FP, the calculation is sent to the data, which makes it easy to parallelize."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "rdd = sc.parallelize(range(100))"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "PythonRDD[1] at RDD at PythonRDD.scala:53"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "rdd.map(lambda x : x+1)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We use the 'map' function of the RDD to send a function to the data.  The function 'map' allows us to pass a function as a parameter to it.\nThe 'lambda' literal creates an anonymous inner function inline.  The lambda function creates a function which takes a parameter x and then does something with it."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "rdd.map(lambda x : x+1).take(10)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "rdd.map(lambda x : x+5).take(10)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Suppose you want to sum up all the elements in a list.  This is also known as Gaussian sum, and has\na closed form solution of n(n - 1)/2, for a list with a certain set of numbers.   But using Spark it can be\ncalculated as follows.  reduce \"rolls up\" the list from left to right.  a contains the intermedia sum and b contains the next item in the list.  Jupyter notebook calls the 'collect' function in order to do the following line of code."
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "5050"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "sc.parallelize(range(1,101)).reduce(lambda a,b: a+b)"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "5050.0"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "n = 101\nn*(n-1)/2"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Thus the parallel computation yields the correct answer."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7 with Spark",
            "language": "python3",
            "name": "python37"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}