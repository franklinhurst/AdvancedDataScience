{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To run this notebook in IBM Watson Studio (for free), click on the button below and then click on the same button again (top right).\n\nIn case you need a (free, never expiring, no credit card needed) IBM Cloud account, you can get one here: [ibm.biz/coursera](https://ibm.biz/coursera) (tracked URL)\n\n[![](https://github.com/romeokienzler/TensorFlow/raw/master/images/playbutton.png)](https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/d94668e2-3d68-4ee2-bc87-00a885803726/view?access_token=76adb4b998e7cb7bed5e53b0c1a99fb99a0b0a7a24498881e766c094845f0366)\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now it's time to install TensorFlow 2.x - as of writing of this notebook, there is only an alpha version available"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n  from cryptography.utils import int_from_bytes\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n  from cryptography.utils import int_from_bytes\nRequirement already satisfied: tensorflow==1.14.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (1.14.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.12.3)\nRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\nRequirement already satisfied: astor>=0.6.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.2)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.27.2)\nRequirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\nRequirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (47.3.1.post20200622)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n"
                }
            ],
            "source": "# the backend needs to be installed first:\n!pip install tensorflow==1.14.0"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now just make sure you restart the Kernel so that the changes take effect:\n\n![](https://github.com/romeokienzler/TensorFlow/raw/master/images/restart_kernel.png)\n\nAfter the kernel has been restarted, we'll check if we are on TensorFlow 2.x"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
                }
            ],
            "source": "import tensorflow as tf"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'1.14.0'"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "tf.__version__"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So this worked out. Now it's time to create and run a keras model. Since MNIST is getting boring, let's use the fashion MNIST dataset. If you want to learn more on the data set check out the following links\n\n[MNIST](https://en.wikipedia.org/wiki/MNIST_database)  \n[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist)\n\nSo in a nutsthell, MNIST contains 60000 28x28 pixel grey scale images of handwritten digits between 0-9 and the corresponding labels. Plus additional 10000 images for testing.\n\nFashing MNIST contains 60000 28x28 pixel grey scale images of fashion articles and the corresponding labels between 0-9. It also contains 10000 test images.\n\nLuckyly, this data set is built in to Keras, so let's load it:"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 0s 0us/step\n"
                }
            ],
            "source": "fashion_mnist = tf.keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n| Label | Description |\n| --- | --- |\n| 0 | T-shirt/top |\n| 1 | Trouser |\n| 2 | Pullover |\n| 3 | Dress |\n| 4 | Coat |\n| 5 | Sandal |\n| 6 | Shirt |\n| 7 | Sneaker |\n| 8 | Bag |\n| 9 | Ankle boot |"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0\n"
                },
                {
                    "data": {
                        "text/plain": "<matplotlib.image.AxesImage at 0x7f2b5115ddd0>"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\ni = 10\nprint(train_labels[i])\nplt.imshow(train_images[i])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As expected, we get 60000 images of 28 by 28 pixels:"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(60000, 28, 28)"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "train_images.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The labels are simply a list of 60000 elements, each one is a number (label) between 0 and 9:"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(60000,)\n[9 0 0 ... 3 0 5]\n"
                }
            ],
            "source": "print(train_labels.shape)\nprint(train_labels)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's have a look at one image:"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.imshow(train_images[0])\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So this is obviously a shoe :) - Let's normalize the data by making sure every pixel value is between 0..1; this is easy in this case:"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "train_images = train_images / 255.0\n\ntest_images = test_images / 255.0"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For those already familiar with Keras might notice, that mainly only the import statements changed. If you are new to Keras, just check out Week 2 of my DeepLearning course on Coursera, you can get it for free in audit mode: http://coursera.org/learn/ai/. So let's start with ordinary Keras by importing some requirements:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In order to write our **hello world** softmax regression model, the following code does the job. If you are familiar with Keras, this is really basic stuff. There is only one catch. The following code doesn't run since the latest stable Keras version is incompatible with the alpha release of TensorFlow 2.0. So the following code is for illustration purposes only. Don't run it, it will destroy your hard drive."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So from a migration and consistency perspective, it would be nice if we just could change the imports and leave our existing Keras code (which we all love) intact, so let's give it a try:"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 17s 289us/sample - loss: 0.4993 - acc: 0.8239 - val_loss: 0.4147 - val_acc: 0.8562\nEpoch 2/5\n60000/60000 [==============================] - 17s 285us/sample - loss: 0.3759 - acc: 0.8643 - val_loss: 0.4210 - val_acc: 0.8450\nEpoch 3/5\n60000/60000 [==============================] - 17s 284us/sample - loss: 0.3371 - acc: 0.8777 - val_loss: 0.3731 - val_acc: 0.8686\nEpoch 4/5\n60000/60000 [==============================] - 18s 294us/sample - loss: 0.3121 - acc: 0.8862 - val_loss: 0.3685 - val_acc: 0.8674\nEpoch 5/5\n60000/60000 [==============================] - 18s 292us/sample - loss: 0.2950 - acc: 0.8919 - val_loss: 0.3526 - val_acc: 0.8733\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2b5273cd10>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.nn import relu\nfrom tensorflow.nn import softmax\n\n\n# Here all the layers of the model are specified at once\n# but it can also be done by starting with just:\n# model = Sequential()\n# and then adding layers one-by-one:\n# model.add(Dense=256, activation=\"sigmoid\", input_shape(784,)) or something with correct dimensions\nmodel = Sequential([\n    Flatten(input_shape=(28, 28)),\n    Dense(128, activation=relu),\n    Dense(10, activation=softmax)\n])\n\n# next the model is compiled with a loss function and an optimizer\nmodel.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n\n# then last, the model is fit on training data\nmodel.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, verbose=1)\n\n#model.evaluate(test_images, test_labels)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you can see, we didn't change the Keras code at all, but now all imports are coming from the tensorflow package. I felt a bit bad when I've noticed that TensorFlow has eaten up Keras, but in reality, nobody uses a Keras runtime other then TensorFlow anyway, so it doesn't really matter. Just be aware that Keras is Google now and part of TensorFlow. In the next notebook, we'll cover the stategies for parallel training. So stay tuned."
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/12\n60000/60000 [==============================] - 207s 3ms/sample - loss: 0.5156 - acc: 0.8171 - val_loss: 0.3553 - val_acc: 0.8738\nEpoch 2/12\n60000/60000 [==============================] - 229s 4ms/sample - loss: 0.3377 - acc: 0.8792 - val_loss: 0.2844 - val_acc: 0.8967\nEpoch 3/12\n60000/60000 [==============================] - 222s 4ms/sample - loss: 0.2896 - acc: 0.8964 - val_loss: 0.2653 - val_acc: 0.9029\nEpoch 4/12\n60000/60000 [==============================] - 225s 4ms/sample - loss: 0.2558 - acc: 0.9068 - val_loss: 0.2472 - val_acc: 0.9079\nEpoch 5/12\n60000/60000 [==============================] - 222s 4ms/sample - loss: 0.2352 - acc: 0.9145 - val_loss: 0.2312 - val_acc: 0.9151\nEpoch 6/12\n60000/60000 [==============================] - 223s 4ms/sample - loss: 0.2119 - acc: 0.9213 - val_loss: 0.2270 - val_acc: 0.9180\nEpoch 7/12\n60000/60000 [==============================] - 221s 4ms/sample - loss: 0.1960 - acc: 0.9265 - val_loss: 0.2259 - val_acc: 0.9192\nEpoch 8/12\n60000/60000 [==============================] - 219s 4ms/sample - loss: 0.1801 - acc: 0.9319 - val_loss: 0.2137 - val_acc: 0.9228\nEpoch 9/12\n60000/60000 [==============================] - 223s 4ms/sample - loss: 0.1710 - acc: 0.9356 - val_loss: 0.2348 - val_acc: 0.9155\nEpoch 10/12\n60000/60000 [==============================] - 228s 4ms/sample - loss: 0.1593 - acc: 0.9400 - val_loss: 0.2076 - val_acc: 0.9255\nEpoch 11/12\n60000/60000 [==============================] - 226s 4ms/sample - loss: 0.1504 - acc: 0.9445 - val_loss: 0.2258 - val_acc: 0.9247\nEpoch 12/12\n60000/60000 [==============================] - 229s 4ms/sample - loss: 0.1400 - acc: 0.9464 - val_loss: 0.2243 - val_acc: 0.9236\n"
                },
                {
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2b50077950>"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n\n\nfrom tensorflow.keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\nx_train = train_images\nx_test = test_images\ny_train = train_labels\ny_test = test_labels\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n#model.compile(loss=keras.losses.categorical_crossentropy,\n        #      optimizer=keras.optimizers.Adadelta(),\n     #         metrics=['accuracy'])\n\nmodel.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "[end]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}